[
  {
    "objectID": "exams/midterm-2.html",
    "href": "exams/midterm-2.html",
    "title": "Extra Practice for Midterm 2",
    "section": "",
    "text": "Problem 1\nConsider a nonnegative, absolutely continuous random variable with cdf\n\\[\nF_X(x)\n=\n\\begin{cases}\n1 - \\exp\\left(-\\frac{x^2}{2}\\right) & x\\geq 0\n\\\\\n0 & x&lt;0.\n\\end{cases}\n\\]\n\nWhat is \\(P(2\\leq X\\leq 3)\\);\nWhat is the density of \\(X\\)?\nWhat is \\(E(X^n)\\) for any \\(n\\in\\mathbb{N}\\)?\nWhat is \\(\\text{var}(X)\\)?\nWhat is the median of \\(X\\)?\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\n\\(P(2\\leq X\\leq 3)=F_X(3)- F_X(2)\\approx 0.124\\);\n\\(f_X(x)=xe^{-x^2/2}\\) for \\(x\\geq 0\\);\n\\(E(X^n)=2^{n/2}\\Gamma(1 + n/2)\\);\n\\(\\text{var}(X)=(4-\\pi)/2\\);\n\\(\\text{median}(X)=\\sqrt{2\\ln 2}\\).\n\n\n\n\n\n\nProblem 2\nLet \\(X\\) be a discrete random variable with\n\n\n\n\\(x\\)\n-1\n3\n7\n\n\n\n\n\\(P(X=x)\\)\n0.5\n0.2\n0.3\n\n\n\n\nCompute the mgf of \\(X\\).\nCompute the mean two ways: using the definition, and using the mgf. Confirm that you get the same answer.\nCompute the variance two ways: using the definition, and using the mgf. Confirm that you get the same answer.\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\n\\(M_X(t)=0.5e^{-t}+0.2e^{3t}+0.3e^{7t}\\) for all \\(t\\in\\mathbb{R}\\);\n\\(E(X)=2.2\\);\n\\(\\text{var}(X)=12.16\\).\n\n\n\n\n\n\nProblem 3\nLet \\(X\\) have density\n\\[\nf_X(x)\n=\n\\frac{1}{2}\ne^{-|x|},\\quad x\\in\\mathbb{R}.\n\\]\n\nWhat is the mgf of \\(X\\)?\nWhat is the mean?\nWhat is the variance?\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\n\\(M_X(t)=1 / (1-t^2)\\) for all \\(-1 &lt; t &lt; 1\\);\n\\(E(X)=0\\);\n\\(\\text{var}(X)=2\\).\n\n\n\n\n\n\nProblem 4\nLet \\(X\\sim\\text{Unif}(0,\\,1)\\), and find the density of \\(Y=X^2\\).\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\\(\\text{Range}(Y)=(0,\\,1)\\) and\n\\[\nf_Y(y) = \\frac{1}{2\\sqrt{y}},\\quad 0&lt;y&lt;1.\n\\]\n\n\n\n\n\nProblem 5\nConsider this joint distribution written in hierarchical form:\n\\[\n\\begin{align*}\nX & \\sim\\text{Unif}(0,\\,1)\\\\\nY\\,|\\,X = x & \\sim \\text{Unif}(0,\\,x).\n\\end{align*}\n\\]\n\nWhat is the joint range?\nWhat is the marginal density of \\(Y\\)?\nWhat is the conditional density of \\(X\\)?\n\n\n\n\n\n\n\nAnswers\n\n\n\n\n\n\n\\(\\text{Range}(X,\\,Y)=\\{(x,\\,y)\\in\\mathbb{R}^2:0&lt;x&lt;1;\\,0&lt;y&lt;x\\}\\);\n\\(f_Y(y)=\\ln(1/y)\\) for \\(0&lt;y&lt;1\\);\n\\(f_{X|Y}(x\\,|\\,y)=\\frac{1}{x\\ln(1/y)}\\) for \\(0&lt;y&lt;x&lt;1\\)."
  },
  {
    "objectID": "syllabus/syllabus_team.html",
    "href": "syllabus/syllabus_team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Mug\nName\nRole\nOffice Hours\n\n\n\n\n\nChen, Andy\nTA\nTue 11:30 PM - 12:30 PM\nFri 1:00 PM - 2:00 PM\nOld Chem 203B\n\n\n\nHuang, Konnie\nTA\nMonTue 1:00 PM - 2:00 PM\nZoom\n\n\n\nJacobson, Gwen\nHead TA\nWed 5:00 PM - 7:00 PM\nOld Chem 025\n\n\n\nZito, John\nInstructor\nTue 2:00 PM - 4:00 PM\nOld Chem 207",
    "crumbs": [
      "Syllabus",
      "Teaching team"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html",
    "href": "syllabus/syllabus_policies.html",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#communication",
    "href": "syllabus/syllabus_policies.html#communication",
    "title": "Policies",
    "section": "",
    "text": "If you wish to ask content-related questions in writing, please do not do so via e-mail. Instead, please use the course discussion forum Ed Discussion. That way all members of the teaching team can see your question, and all students can benefit from the ensuing discussion. You are also encouraged to answer one another’s questions.\nIf you have questions about personal matters that may not be appropriate for the public course forum (e.g. illness, accommodations, etc), then please e-mail the instructor directly (john.zito@duke.edu).\n\n\n\n\n\n\nNote\n\n\n\nYou can ask questions anonymously on Ed. The teaching team will still know your identity, but your peers will not.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "href": "syllabus/syllabus_policies.html#late-work-and-extensions",
    "title": "Policies",
    "section": "Late work and extensions",
    "text": "Late work and extensions\nNo late work will be accepted unless you request an extension in advance by e-mailing the instructor directly (john.zito@duke.edu). All reasonable requests will be entertained, but extensions will not be long.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#regrade-requests",
    "href": "syllabus/syllabus_policies.html#regrade-requests",
    "title": "Policies",
    "section": "Regrade requests",
    "text": "Regrade requests\nIf you receive a graded assignment back, and you believe that some part of it was graded incorrectly, you may dispute the grade by submitting a regrade request in Gradescope. Note the following:\n\nYou have one week after you receive a grade to submit a regrade request;\nYou should submit separate regrade requests for each question you wish to dispute, not a single catch-all request;\nRequests will be considered if there was an error in the grade calculation or if a correct answer was mistakenly marked as incorrect;\nRequests to dispute the number of points deducted for an incorrect response will not be considered;\nRegrade requests are not a mechanism for asking for clarification on feedback. Those questions should be brought to office hours;\nNo grades will be changed after the final exam has been administered on Saturday May 3;\n\n\n\n\n\n\n\nWarning\n\n\n\nA regrade request can result in your grade going up, staying the same, or going down if we determine that, in fact, the original grader was too lenient.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#attendance",
    "href": "syllabus/syllabus_policies.html#attendance",
    "title": "Policies",
    "section": "Attendance",
    "text": "Attendance\nLive your life. Attendance is not strictly required for any of the class meetings. The responsibility lies with us to make class meetings sufficiently engaging and informative that you choose to attend. Having said that, success in this class and regular attendance are probably highly positively correlated. Furthermore, while lab attendance is not required, regular attendance is most likely the path of least resistance to earning full credit for the lab component of your final grade. The labs are designed so that they can be completed in one sitting more or less, and they are due at midnight the same day. So show up to lab, bang it out, and move on with your life.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#accommodations",
    "href": "syllabus/syllabus_policies.html#accommodations",
    "title": "Policies",
    "section": "Accommodations",
    "text": "Accommodations\nIf you need accommodations for this class, you will need to register with the Student Disability Access Office (SDAO) and provide them with documentation related to your needs. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#collaboration",
    "href": "syllabus/syllabus_policies.html#collaboration",
    "title": "Policies",
    "section": "Collaboration",
    "text": "Collaboration\nYou are encouraged to discuss and collaborate on problem sets and labs, but all submitted work must be entirely your own. You should not be sharing your solutions or copying other people’s work. This will be treated as plagiarism, and both the sharer and the recipient(s) will be penalized equally.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "href": "syllabus/syllabus_policies.html#use-of-outside-resources-including-ai",
    "title": "Policies",
    "section": "Use of outside resources, including AI",
    "text": "Use of outside resources, including AI\nIt basically comes down to this:\n\nDo your own math and write your own words, but write code however you want (as long as you cite your sources).\n\nYou are expected to produce all mathematical reasoning, arguments, and calculations yourself, and your write-ups should be original to you. You should not use ChatGPT or anything like it to solve math problems or write words for you. When it comes to code, you are free to use any outside resources (StackOverflow, ChatGPT, etc) to help you complete coding tasks as long as you cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n\n\n\n\n\n\nCiting an LLM like ChatGPT\n\n\n\nHere are some general guidelines for citing AI-generated content. In this class, if you use something like ChatGPT to help you, you need to cite that by providing a direct link to the conversation you had with the bot, like this: https://chatgpt.com/share/677c4060-1d58-8008-8e47-5caa5556a825. You can generate such a link here:",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_policies.html#duke-community-standard",
    "href": "syllabus/syllabus_policies.html#duke-community-standard",
    "title": "Policies",
    "section": "Duke Community Standard",
    "text": "Duke Community Standard\nAs a student in this course, you have agreed to uphold the Duke Community Standard and the practices specific to this course.\n\n\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will automatically results in a zero for the relevant portion or the entire assignment, and will be reported to the Office of Student Conduct & Community Standards for further action. Furthermore:\n\nIf a conduct violation results in a zero on a lab or problem set, that zero will not be dropped;\nIf a conduct violation results in a zero on an midterm, that zero will not be replaced with your final exam score;\nIf we discover that students are sharing and copying assignment solutions, all students involved will be penalized equally, the sharer the same as the recipients.",
    "crumbs": [
      "Syllabus",
      "Policies"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html",
    "href": "syllabus/syllabus_materials.html",
    "title": "Course materials",
    "section": "",
    "text": "You are not required to purchase a textbook for this class. I strive to make the lectures self-contained and sufficient for all of the assignments. However, if you wish to follow along with one, these are all good options:\n\n[Ross] A First Course in Probability by Sheldon Ross;\n[HTZ] Probability and Statistical Inference by Robert Hogg, Elliot Tanis, and Dale Zimmerman;\n[DS] Probability and Statistics by Morris Degroot and Mark Schervish;\n[Wass] All of Statistics by Larry Wasserman.\n\nIn the PREPARE column of the course schedule, I will indicate which parts of a book correspond to the lectures.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#textbooks",
    "href": "syllabus/syllabus_materials.html#textbooks",
    "title": "Course materials",
    "section": "",
    "text": "You are not required to purchase a textbook for this class. I strive to make the lectures self-contained and sufficient for all of the assignments. However, if you wish to follow along with one, these are all good options:\n\n[Ross] A First Course in Probability by Sheldon Ross;\n[HTZ] Probability and Statistical Inference by Robert Hogg, Elliot Tanis, and Dale Zimmerman;\n[DS] Probability and Statistics by Morris Degroot and Mark Schervish;\n[Wass] All of Statistics by Larry Wasserman.\n\nIn the PREPARE column of the course schedule, I will indicate which parts of a book correspond to the lectures.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "syllabus/syllabus_materials.html#technology",
    "href": "syllabus/syllabus_materials.html#technology",
    "title": "Course materials",
    "section": "Technology",
    "text": "Technology\nLecture will largely be a low tech affair: pencil and paper should be sufficient most of the time. You should plan to bring a laptop or tablet device to lab. In general, you will need access to a device with internet so that you can use the following:\n\nThis course page that you are on right now;\nR/RStudio via the Duke Container Manager;\nCanvas, through which you can access…\n\nGradescope;\nEd Discussion;\n\nZoom (e.g. for remote office hours).\n\nIf access to technology becomes a concern for you during the semester, contact the instructor immediately to discuss options.",
    "crumbs": [
      "Syllabus",
      "Materials"
    ]
  },
  {
    "objectID": "slides/slides_2025_01_08.html#welcome-to-sta-240",
    "href": "slides/slides_2025_01_08.html#welcome-to-sta-240",
    "title": "Welcome to STA 240!",
    "section": "Welcome to STA 240!",
    "text": "Welcome to STA 240!\n\n\nWhile you wait, please complete this brief questionnaire:"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#teaching-team",
    "href": "slides/slides_2025_01_08.html#teaching-team",
    "title": "Welcome to STA 240!",
    "section": "Teaching Team",
    "text": "Teaching Team\n\n\n\nMug\nName\nRole\nOffice Hours\n\n\n\n\n\nChen, Andy\nTA\nTBD\n\n\n\nHuang, Konnie\nTA\nTBD\n\n\n\nJacobson, Gwen\nHead TA\nTBD\n\n\n\nZito, John\nInstructor\nTue 2pm - 4pm"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-birthday-problem",
    "href": "slides/slides_2025_01_08.html#example-the-birthday-problem",
    "title": "Welcome to STA 240!",
    "section": "Example: the birthday problem",
    "text": "Example: the birthday problem\n\\(k\\) people convene for a birthday party:\n\nWhat is the probability that at least two of the attendees share a birthday?\nHow many people need to show up to the party for there to be a 50% chance of at least one match?\n\nMost people guess that you need a hundred or more people.\n\nIn fact, you only need 23."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-birthday-problem-1",
    "href": "slides/slides_2025_01_08.html#example-the-birthday-problem-1",
    "title": "Welcome to STA 240!",
    "section": "Example: the birthday problem",
    "text": "Example: the birthday problem\n\n\n\nno. of attendees (k)\nProb(at least one bday match)\n\n\n\n\n1\n0%\n\n\n4\n1.6%\n\n\n16\n28%\n\n\n23\n50.7%\n\n\n40\n89%\n\n\n56\n98%\n\n\n60\n99.4\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n366\n100.0%\n\n\n\nKey words: binomial coefficient, pigeonhole principle"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-birthday-problem-2",
    "href": "slides/slides_2025_01_08.html#example-the-birthday-problem-2",
    "title": "Welcome to STA 240!",
    "section": "Example: the birthday problem",
    "text": "Example: the birthday problem"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-monty-hall-problem",
    "href": "slides/slides_2025_01_08.html#example-the-monty-hall-problem",
    "title": "Welcome to STA 240!",
    "section": "Example: the Monty Hall problem",
    "text": "Example: the Monty Hall problem\nLet’s play: https://montyhall.io/\n\n\n\n\n\n\n\n\n\n\n\n\nVery counterintuitive\n\n\nMost people start out thinking that the two doors are equally likely to contain the prize, so switching doesn’t matter. In fact, you have a 2/3 chance of winning if you switch."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-wisdom-of-crowds",
    "href": "slides/slides_2025_01_08.html#example-the-wisdom-of-crowds",
    "title": "Welcome to STA 240!",
    "section": "Example: the wisdom of crowds",
    "text": "Example: the wisdom of crowds\n\n\n\n\nAt a 1906 country fair in Plymouth, 800 people participated in a contest to estimate the weight of an ox. Francis Galton observed that the median guess, 1207 lbs, was accurate within 1% of the true weight of 1198 lbs.\n\n\n\n\n\n\n\n\n\nLesson\n\n\nThe aggregation of many imperfect estimates/guesses is often better than a needle-in-haystack search for the “best” individual guess.\n\n\n\n\n\n\n\n\n\n\n\nReality check!\n\n\nIt took humans a long time to realize this. The first recorded uses of an “average” were during Isaac Newton’s lifetime (see Stigler’s Seven Pillars of Statistical Wisdom)."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-wisdom-of-crowds-1",
    "href": "slides/slides_2025_01_08.html#example-the-wisdom-of-crowds-1",
    "title": "Welcome to STA 240!",
    "section": "Example: the wisdom of crowds",
    "text": "Example: the wisdom of crowds\n\n\n\n\n\n\nIt’s a lesson we are doomed to relearn often, apparently.\n\n\n (source: CNN)"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-folly-of-doctors",
    "href": "slides/slides_2025_01_08.html#example-the-folly-of-doctors",
    "title": "Welcome to STA 240!",
    "section": "Example: the folly of doctors",
    "text": "Example: the folly of doctors\n\nA 50-year-old, asymptomatic woman tests positive for breast cancer. Alarming, but no diagnostic test is perfect. If the prevalence of breast cancer in the population is 1%, if the false negative rate of the test is 10%, and if the false positive rate is 9%, what is the chance that the woman actually has cancer, given that she tested positive?\n\n\nYou will know how to answer this by February. Doctors though…\n\n\n\n\n\n\nBBC News 2014\n\n\nOnly 34 out of 160 surveyed gynecologist got it right (9%). Almost half of them said 90%.\n\nWe can only imagine how much anxiety those innumerate doctors instil in women."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#reason-1-its-necessary.-1",
    "href": "slides/slides_2025_01_08.html#reason-1-its-necessary.-1",
    "title": "Welcome to STA 240!",
    "section": "Reason 1: It’s necessary.",
    "text": "Reason 1: It’s necessary.\n\n\n\n\nHuman intuition and “common sense” about probability and statistics are often just flat out wrong, in silly and dangerous ways. Mere mortals require the scaffolding of mathematics to discipline our thinking."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#new-title-the-unreasonable-effectiveness-of-probability-ineverything",
    "href": "slides/slides_2025_01_08.html#new-title-the-unreasonable-effectiveness-of-probability-ineverything",
    "title": "Welcome to STA 240!",
    "section": "New title: The Unreasonable Effectiveness of Probability in…Everything?",
    "text": "New title: The Unreasonable Effectiveness of Probability in…Everything?\n\n\n\n\n\n\nRead it!"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-llms",
    "href": "slides/slides_2025_01_08.html#example-llms",
    "title": "Welcome to STA 240!",
    "section": "Example: LLMs",
    "text": "Example: LLMs\n\n\n\n\n\n\nQuestion\n\n\nWhat method does ChatGPT use to generate the next word in one of its responses?\n\n\n\n\nLet’s ask! https://chatgpt.com/share/677ef289-9564-8008-a662-9f8c2cfb04fc"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-portfolio-selection",
    "href": "slides/slides_2025_01_08.html#example-portfolio-selection",
    "title": "Welcome to STA 240!",
    "section": "Example: portfolio selection",
    "text": "Example: portfolio selection\n\n\n\n\n\n\nProblem\n\n\nHow do you optimally allocate your savings to different assets (stocks vs bonds, Apple stock vs Microsoft, etc)?\n\n\n\n\n\n\n\n\n\nObjective\n\n\nYou want to make the most stable and lucrative choice possible, subject to uncertainty about how the competing assets will ultimately perform.\n\n\n\n\n\n\n\n\n\nThoroughly Modern Markowitz\n\n\nThe mathematics of this won a Nobel Prize in Economic Sciences in 1990, but it’s “just” the creative application of basic probability."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-the-mathematics-of-insurance",
    "href": "slides/slides_2025_01_08.html#example-the-mathematics-of-insurance",
    "title": "Welcome to STA 240!",
    "section": "Example: the mathematics of insurance",
    "text": "Example: the mathematics of insurance\nWhen an insurance company sells you a policy, they are making a bet that you won’t need it – that you’ll pay them but they won’t ultimately pay you. They make thousands of such bets, and if everyone makes a claim, the company is ruined. How do they navigate this uncertainty?\n\n\n\n\n\n\n\nActuarial mathematics!\n\n\nEvery insurance company employs armies of actuaries, certified professionals with a deep understanding of probability and statistics, to help them make decisions about profit, loss, and risk of ruin."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#example-mathematical-biology",
    "href": "slides/slides_2025_01_08.html#example-mathematical-biology",
    "title": "Welcome to STA 240!",
    "section": "Example: mathematical biology",
    "text": "Example: mathematical biology\nThe metastasis of cancer cells is frequently modeled using something called a branching process, a kind of random evolution process that builds on the fundamentals of our course:"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#reason-2-its-useful",
    "href": "slides/slides_2025_01_08.html#reason-2-its-useful",
    "title": "Welcome to STA 240!",
    "section": "Reason 2: It’s useful",
    "text": "Reason 2: It’s useful\n\n\n\n\nLearning probability theory gives you serious wings to study large swathes of science and technology."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#take-it-away-boys",
    "href": "slides/slides_2025_01_08.html#take-it-away-boys",
    "title": "Welcome to STA 240!",
    "section": "Take it away, boys…",
    "text": "Take it away, boys…\n\n\n\n\n\n\nBertrand Russell, Mysticism and Logic and Other Essays (1917)\n\n\nMathematics, rightly viewed, possesses not only truth, but supreme beauty cold and austere, like that of sculpture, without appeal to any part of our weaker nature, without the gorgeous trappings of painting or music, yet sublimely pure, and capable of a stern perfection such as only the greatest art can show.\n\n\n\n\n\n\n\n\n\nAlbert Einstein, “The Late Emmy Noether” (1935)\n\n\nPure mathematics is, in its way, the poetry of logical ideas."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#this-is-a-theorem-we-will-prove",
    "href": "slides/slides_2025_01_08.html#this-is-a-theorem-we-will-prove",
    "title": "Welcome to STA 240!",
    "section": "This is a theorem we will prove:",
    "text": "This is a theorem we will prove:"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#reason-3-its-beautiful",
    "href": "slides/slides_2025_01_08.html#reason-3-its-beautiful",
    "title": "Welcome to STA 240!",
    "section": "Reason 3: It’s beautiful",
    "text": "Reason 3: It’s beautiful\n\n\n\n\nDiscerning elegant patterns within “random” behavior can be very aesthetically pleasing."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#why-study-mathematical-probstat",
    "href": "slides/slides_2025_01_08.html#why-study-mathematical-probstat",
    "title": "Welcome to STA 240!",
    "section": "Why study mathematical probstat?",
    "text": "Why study mathematical probstat?\n\n\nIt’s necessary.\n\nHumans suck at thinking about this stuff.\n\nIt’s useful.\n\nIt makes studying other things so much easier.\n\nIt’s beautiful.\n\nThis is the main reason, honestly.\n\n\n\n\nSound good?"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#bookmark-the-course-page",
    "href": "slides/slides_2025_01_08.html#bookmark-the-course-page",
    "title": "Welcome to STA 240!",
    "section": "Bookmark the course page!",
    "text": "Bookmark the course page!\n\n\n\n\n\n\n\n\nhttps://sta240-s25.github.io/"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#final-grade-breakdown",
    "href": "slides/slides_2025_01_08.html#final-grade-breakdown",
    "title": "Welcome to STA 240!",
    "section": "Final grade breakdown",
    "text": "Final grade breakdown\nYour final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nLabs\n10%\n\n\nProblem Sets\n30%\n\n\nMidterm Exam 1\n20%\n\n\nMidterm Exam 2\n20%\n\n\nFinal exam\n20%\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThe final letter grade will be based on the usual thresholds, which will not change and will be applied exactly. So no curve and no rounding."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#sowheres-the-wiggle-room",
    "href": "slides/slides_2025_01_08.html#sowheres-the-wiggle-room",
    "title": "Welcome to STA 240!",
    "section": "So…where’s the wiggle room?",
    "text": "So…where’s the wiggle room?\n\nWe drop the two lowest labs;\nWe drop the lowest problem set;\nWe will replace your lowest midterm score with your final exam score (if it’s better)."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#labs-10",
    "href": "slides/slides_2025_01_08.html#labs-10",
    "title": "Welcome to STA 240!",
    "section": "Labs (10%)",
    "text": "Labs (10%)\nLed by Gwen in Perkins LINK 071 (Classroom 5):\n\nThursday 1:25 PM - 2:40 PM;\nThursday 3:05 PM - 4:20 PM.\n\nGuided activities introducing you to special topics, extensions, applications, and case studies. We will also introduce some basic R stuff, and we will use Quarto for the lab write-ups.\n\n\n\n\n\n\nPlan to attend regularly\n\n\nDesigned to be complete-able during the lab period, but due by 11:59 PM that same day."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#problem-sets-30",
    "href": "slides/slides_2025_01_08.html#problem-sets-30",
    "title": "Welcome to STA 240!",
    "section": "Problem Sets (30%)",
    "text": "Problem Sets (30%)\n\nMostly pencil-and-paper math problems, with some coding thrown in occasionally;\nCompose solutions however you want: scan or photograph written work, handwriting capture, LaTeX, Quarto, whatever;\nSubmit a single PDF in Gradescope (and mark your pages!)\n\n\n\n\n\n\n\nLate policy\n\n\nNo late work will be accepted unless you request an extension in advance by e-mailing JZ. All reasonable requests will be entertained, but extensions will not be long."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#exams-20-each",
    "href": "slides/slides_2025_01_08.html#exams-20-each",
    "title": "Welcome to STA 240!",
    "section": "Exams (20% each)",
    "text": "Exams (20% each)\nTraditional, in-class, written exams:\n\nMidterm 1: Monday February 17;\nMidterm 2: Monday March 31;\nFinal Exam: Saturday May 3.\n\n\n\n\n\n\n\nWhat can I use during the exam?\n\n\nNo resources except an 8.5” x 11” note sheet created by you and only you.\n\n\n\n\n\n\n\n\n\nIf you need testing accommodations…\n\n\nMake sure I get a letter, and make your appointments in the Testing Center now."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#attendance",
    "href": "slides/slides_2025_01_08.html#attendance",
    "title": "Welcome to STA 240!",
    "section": "Attendance",
    "text": "Attendance\nNot required. Live your life."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#communication",
    "href": "slides/slides_2025_01_08.html#communication",
    "title": "Welcome to STA 240!",
    "section": "Communication",
    "text": "Communication\nIf you wish to ask questions in writing…\n\nPost on Ed: stuff about general course policies and content;\nEmail JZ directly: stuff specific to your personal circumstances.\n\nYou should not really be emailing the TAs directly for any reason."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#collaboration",
    "href": "slides/slides_2025_01_08.html#collaboration",
    "title": "Welcome to STA 240!",
    "section": "Collaboration",
    "text": "Collaboration\nYou are encouraged to work together on labs and problem sets, but you should not copy off one another or share solutions. All submitted work must be entirely your own.\n\n\n\n\n\n\nWarning\n\n\nIf we discover violations of this policy, everyone involved (sharers and recipients alike) will receive a zero on the assignment and be referred to the conduct office.\nA zero score resulting from a conduct violation will not be dropped or replaced."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#use-of-outside-resources-including-ai",
    "href": "slides/slides_2025_01_08.html#use-of-outside-resources-including-ai",
    "title": "Welcome to STA 240!",
    "section": "Use of outside resources, including AI",
    "text": "Use of outside resources, including AI\nSay it with me:\n\nDo your own math and write your own words, but write code however you want (as long as you cite your sources).\n\n\nYou are generally discouraged from consulting outside resources. The textbooks, notes, and discussion forum should be self-contained and sufficient. If you find that this is false, let me know and we will get you what you need;\nHopefully our coding needs are sufficiently basic that you don’t feel the need to use outside resources too often, but telling you not to use Google etc while coding is just insane. It’s fine as long as you cite it."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#what-level-of-mathematics-should-you-expect",
    "href": "slides/slides_2025_01_08.html#what-level-of-mathematics-should-you-expect",
    "title": "Welcome to STA 240!",
    "section": "What level of mathematics should you expect?",
    "text": "What level of mathematics should you expect?\nThis is essentially a pencil-and-paper math class. We will use all of the basic skills taught in Calc I and II:\n\n\ndifferentiation (power rule, chain rule, all that)\nintegration (FTOC, improper integrals, substitution, by parts…)\nlimits and continuity (L’Hôpital’s rule, etc)\ninfinite series (Taylor series for \\(e^x\\), anyone?)\n\n\n\nREVIEW: Problem Set 0 is due 12PM Thursday January 16.\n\n\n\n\n\n\n\n\nThis is not sink-or-swim.\n\n\nLab on Thursday January 9 is a review session and work period for this assignment."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#probability",
    "href": "slides/slides_2025_01_08.html#probability",
    "title": "Welcome to STA 240!",
    "section": "Probability",
    "text": "Probability\nState the distribution (probability rules) of some random phenomenon, and then study how the realizations of that phenomenon “typically” behave:\n\n\nGiven a fair coin, how many flips will it take on average until I observe the first head?\n\n\n\nselect a phenomenon to study (the outcome of a coin flip);\nfully specify its distribution (it’s a fair, 50-50 coin);\nstudy typical behavior of realizations (how many flips on average until the first head?)."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#statistics-is-probability-in-reverse",
    "href": "slides/slides_2025_01_08.html#statistics-is-probability-in-reverse",
    "title": "Welcome to STA 240!",
    "section": "Statistics is “probability in reverse”",
    "text": "Statistics is “probability in reverse”\nStart with the realizations of a random phenomenon with unknown distribution, and try to use those realizations to figure out what the distribution is:\n\n\nImagine that you are given an unfamiliar coin, and you do not know anything about its properties. So you flip it 25 times, and on the basis of those 25 flips, you try to decide whether or not the coin is fair.\n\n\n\nIn probability, we assumed that the coin was fair, and then reasoned from that. In statistics, we do not do this. We start with some coin, which may or may not be fair, and then we try to “infer” its properties."
  },
  {
    "objectID": "slides/slides_2025_01_08.html#probability-and-statistics",
    "href": "slides/slides_2025_01_08.html#probability-and-statistics",
    "title": "Welcome to STA 240!",
    "section": "Probability and statistics",
    "text": "Probability and statistics\n\n\n\n\n\n\n\n\n\n\n\n\nProbability\nForward problem\nDeductive\nReasons from rules to consequences\n\n\nStatistics\nInverse problem\nInductive\nObserves consequences, and infers rules"
  },
  {
    "objectID": "slides/slides_2025_01_08.html#the-philosophy-of-probability",
    "href": "slides/slides_2025_01_08.html#the-philosophy-of-probability",
    "title": "Welcome to STA 240!",
    "section": "The philosophy of probability",
    "text": "The philosophy of probability\nTwo common interpretive perspectives:\n\n\nFrequentist: probability describes the long run frequency of repeatable events;\nSubjective: probability describes an observer’s subjective experience of uncertainty.\n\n\n\n\n\n\n\n\n\nNote\n\n\nLike the wave-particle duality of light, both are true and useful, but their coexistence can be tense and uneasy. We just have to learn to live with that.\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nRegardless your interpretation, the mathematics of probability is the same."
  },
  {
    "objectID": "psets/pset_1.html",
    "href": "psets/pset_1.html",
    "title": "Problem Set 1",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-0",
    "href": "psets/pset_1.html#problem-0",
    "title": "Problem Set 1",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-1",
    "href": "psets/pset_1.html#problem-1",
    "title": "Problem Set 1",
    "section": "Problem 1",
    "text": "Problem 1\nPersi Diaconis is a famous researcher in probability and statistics. He has a cute line of research where he probes the randomness that we take for granted in simple things like coin tossing, dice, and playing cards. In this Numberphile interview, he discusses coin tossing, and says both “coin tossing is as close to a random phenomenon as I know” and “coin tossing is a deterministic process. What’s random about it?” Wut?\nWatch the interview, and report back with a brief summary of Diaconis’ explanation of what makes a coin toss random. Do you agree or disagree?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-2",
    "href": "psets/pset_1.html#problem-2",
    "title": "Problem Set 1",
    "section": "Problem 2",
    "text": "Problem 2\nTake \\(\\mathbb{R}\\) to be your reference set, and consider these subsets: \\[\n\\begin{align*}\nA&=[1,\\,5]\\\\\nB&=\\{x\\in\\mathbb{R}\\,:\\,|x|&gt;2\\}\\\\\nC&=(-\\infty,\\,0].\n\\end{align*}\n\\] Express each of the following in as simplified and concise a form as possible:\n\n\\(A^c\\)\n\\(A \\cup B\\)\n\\(B \\cap C^c\\)\n\\(A^c \\cap B^c \\cap C^c\\)\n\\((A \\cup B) \\cap C\\)",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-3",
    "href": "psets/pset_1.html#problem-3",
    "title": "Problem Set 1",
    "section": "Problem 3",
    "text": "Problem 3\n“Prove” De Morgan’s second law with a picture:\n\\[\n(A\\cap B)^{c}=A^{c}\\cup B^{c}.\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-4",
    "href": "psets/pset_1.html#problem-4",
    "title": "Problem Set 1",
    "section": "Problem 4",
    "text": "Problem 4\nProve that\n\\[\nP(A)+P(B)-1\\leq P(A\\cap B).\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-5",
    "href": "psets/pset_1.html#problem-5",
    "title": "Problem Set 1",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(A\\) and \\(B\\) be events in a sample space \\(S\\). Let \\(C\\) be the set of outcomes that are in either \\(A\\) or \\(B\\), but not both.\n\nDraw a well-labeled picture of \\(S\\), \\(A\\), \\(B\\), and \\(C\\).\nWrite down a formula for \\(C\\) in terms of \\(A\\) and \\(B\\) using any of the basic operations: union, intersection, complement.\nProve that\n\n\\[\nP(C)=P(A)+P(B)-2P(A\\cap B).\n\\]\n\nExplain this result conceptually (with words and pictures).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-6",
    "href": "psets/pset_1.html#problem-6",
    "title": "Problem Set 1",
    "section": "Problem 6",
    "text": "Problem 6\nLet \\(S\\) be a sample space, and consider events \\(A,\\, B,\\, C\\subseteq S\\). Recall that the law of inclusion/exclusion says that\n\\[\nP(A\\cup B)=P(A)+P(B)-P(A\\cap B).\n\\]\n\nHow should this be extended to unions of three events? \\[\nP(A\\cup B\\cup C)=P(A)+P(B)+P(C)+...{???}\n\\] Explain your conjecture with words and pictures.\nProve your conjecture.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#problem-7",
    "href": "psets/pset_1.html#problem-7",
    "title": "Problem Set 1",
    "section": "Problem 7",
    "text": "Problem 7\nSuppose we have the sample space \\(S=\\mathbb{N}=\\{0,\\,1,\\,2,\\,...\\}\\) and a probability measure \\(P\\) that assigns the following individual probabilities to the singleton sets: \\[\nP(\\{i\\})=c\\frac{4^i}{i!},\\quad i\\in\\mathbb{N}.\n\\]\n\nIn order for \\(P\\) to satisfy the axiom of total measure one, what must be the value of the constant \\(c&gt;0\\).\nWhich outcome(s) in the sample space are most likely (ie have the largest individual probability of occurring)?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#submission",
    "href": "psets/pset_1.html#submission",
    "title": "Problem Set 1",
    "section": "Submission",
    "text": "Submission\nYou are free to compose your solutions for this problem set however you wish (scan or photograph written work, handwriting capture on a tablet device, LaTeX, Quarto, whatever) as long as the final product is a single PDF file. You must upload this to Gradescope and mark the pages associated with each problem.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_1.html#point-values",
    "href": "psets/pset_1.html#point-values",
    "title": "Problem Set 1",
    "section": "Point values",
    "text": "Point values\n\n\n\nProblem\nPoints\n\n\n\n\n1\n5\n\n\n2.a\n2\n\n\n2.b\n2\n\n\n2.c\n2\n\n\n2.d\n2\n\n\n2.e\n2\n\n\n3\n5\n\n\n4\n5\n\n\n5.a\n2\n\n\n5.b\n2\n\n\n5.c\n5\n\n\n5.d\n1\n\n\n6.a\n5\n\n\n6.b\n5\n\n\n7.a\n5\n\n\n7.b\n5\n\n\nTOTAL\n55",
    "crumbs": [
      "Problem Sets",
      "Problem Set 1"
    ]
  },
  {
    "objectID": "psets/pset_2.html",
    "href": "psets/pset_2.html",
    "title": "Problem Set 2",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-0",
    "href": "psets/pset_2.html#problem-0",
    "title": "Problem Set 2",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-1",
    "href": "psets/pset_2.html#problem-1",
    "title": "Problem Set 2",
    "section": "Problem 1",
    "text": "Problem 1\nSeven balls are randomly withdrawn from an urn that contains 12 red, 16 blue, and 18 green balls. Find the probability that\n\n3 red, 2 blue, and 2 green balls are withdrawn;\nat least 2 red balls are withdrawn;\nall withdrawn balls are the same color;\neither exactly 3 red balls or exactly 3 blue balls are withdrawn.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-2",
    "href": "psets/pset_2.html#problem-2",
    "title": "Problem Set 2",
    "section": "Problem 2",
    "text": "Problem 2\nSuppose you are dealt six cards from a well-shuffled, standard deck of 52.\n\nWhat is the probability of getting 3 of one rank and 3 of another?\nWhat is the probability of getting 4 of one rank and 2 of another?\nWhat is the probability of getting 3 aces and 3 of another rank?\nWhat is the probability of getting 4 of one rank and 2 aces?\nWhat is the probability that all 6 cards are in the same suit?\nWhat is the probability that all 6 cards are consecutive (ie a hand with 3 hearts, 4 spades, 5 spades, 6 clubs, 7 hearts, and the 8 diamonds)? Assume that the ace can only be the high card;\nWhat is the answer to the previous question if we allow the ace to be either high or low?\nWhat is the probability of receiving the ace, king, queen, jack, 10 and 9 all in hearts?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-3",
    "href": "psets/pset_2.html#problem-3",
    "title": "Problem Set 2",
    "section": "Problem 3",
    "text": "Problem 3\nIn an election, candidate \\(A\\) received 2,656 votes, and candidate \\(B\\) received 2,594 votes. So \\(A\\) won. Then it was discovered that 136 ineligible people had voted. A judge ruled that the election should be redone from scratch. Candidate \\(A\\) appealed this ruling, arguing that if the 136 ineligible votes were randomly reallocated to the two candidates, the probability that the election results change would be extremely small.\n\nWhat is the probability that \\(m\\) of the 136 ineligible votes were cast for candidate \\(A\\)? Treat \\(m\\) as an arbitrary constant in \\(\\{0,\\,1,\\,2,\\,...,\\,136\\}\\);\nFor what values of \\(m\\) would the results change?\nWhat is the probability that the results would change?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-4",
    "href": "psets/pset_2.html#problem-4",
    "title": "Problem Set 2",
    "section": "Problem 4",
    "text": "Problem 4\nLet \\(A\\) and \\(B\\) be independent events. Prove that \\(A^c\\) and \\(B^c\\) are independent events.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-5",
    "href": "psets/pset_2.html#problem-5",
    "title": "Problem Set 2",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(S\\) be a sample space and \\(B\\subseteq S\\) be an event with \\(P(B)&gt;0\\). Show that the function \\(G(A)=P(A\\,|\\, B)\\) is a probability measure on \\(S\\). That is, show that \\(G\\) satisfies the axioms: total measure 1, nonegativity, countable additivity.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-6",
    "href": "psets/pset_2.html#problem-6",
    "title": "Problem Set 2",
    "section": "Problem 6",
    "text": "Problem 6\nAssume that \\(P(A)&gt;0\\) and prove that\n\\[\nP(A\\cap B\\,|\\, A)\\geq P(A\\cap B\\,|\\, A\\cup B).\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-7",
    "href": "psets/pset_2.html#problem-7",
    "title": "Problem Set 2",
    "section": "Problem 7",
    "text": "Problem 7\nAn encryption algorithm generates a seed value \\(z\\) in the following way:\n\nA binary operator is chosen at random from \\(\\{+,\\,\\cdot\\}\\);\nTwo distinct numbers \\(x\\) and \\(y\\) are chosen at random from the set \\(\\{1,\\,2,\\,...,\\,9\\}\\) and the binary operation chosen above acts on \\(x\\) and \\(y\\) to produce \\(z\\).\n\n\nWhat is the probability that \\(z\\) is an even number?\nYou notice that the algorithm generates an even \\(z\\) value. Given this, what is the probability that the \\(+\\) operator was used to generate it?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-8",
    "href": "psets/pset_2.html#problem-8",
    "title": "Problem Set 2",
    "section": "Problem 8",
    "text": "Problem 8\nA pair of fair dice is rolled until a sum of either a 5 or a 7 appears. What is the probability that a 5 occurs first?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-9",
    "href": "psets/pset_2.html#problem-9",
    "title": "Problem Set 2",
    "section": "Problem 9",
    "text": "Problem 9\n\n\n\n\n\nThe figure above displays a circuit. Switch \\(S_i\\) closes with probability \\(p_i\\), and the switches close independently of one another. What is the probability that electricity can flow from \\(A\\) to \\(G\\)?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#problem-10",
    "href": "psets/pset_2.html#problem-10",
    "title": "Problem Set 2",
    "section": "Problem 10",
    "text": "Problem 10\nConsider the “extended” Monty Hall problem:\n\nthere are \\(n\\) doors. A car is behind one door and goats are behind the other \\(n-1\\) doors;\nthe contestant selects one door. Instead of opening that door, the game show host then opens \\(0 \\leq k \\leq n-2\\) of the remaining doors to reveal \\(k\\) goats. Note that \\(k\\) must not exceed \\(n-2\\), since the host does not open your door or the door with the car;\nthe contestant is given an option: either they can stay with their originally chosen door or they can switch to one of the other remaining door that the host did not open.\n\nWhat is the probability that switching your choice of door results in a win?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_2.html#submission",
    "href": "psets/pset_2.html#submission",
    "title": "Problem Set 2",
    "section": "Submission",
    "text": "Submission\nYou are free to compose your solutions for this problem set however you wish (scan or photograph written work, handwriting capture on a tablet device, LaTeX, Quarto, whatever) as long as the final product is a single PDF file. You must upload this to Gradescope and mark the pages associated with each problem.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 2"
    ]
  },
  {
    "objectID": "psets/pset_6.html",
    "href": "psets/pset_6.html",
    "title": "Problem Set 6",
    "section": "",
    "text": "something with hierarchies again\nsome applied word problem\ncovariance\nsums and average\nsomething with simulation"
  },
  {
    "objectID": "psets/pset_5.html",
    "href": "psets/pset_5.html",
    "title": "Problem Set 5",
    "section": "",
    "text": "Each part of each problem on this set is worth one point, and they will each be graded on the following scale:\nThis assignment contains a total of 40 points, but it will be graded out of 30. So if you do extra problems, you get extra credit. For example, if you do every problem, and you nail them all, then that appears as a 40 / 30 in Canvas toward the problem set component of your final course grade.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-1",
    "href": "psets/pset_5.html#problem-1",
    "title": "Problem Set 5",
    "section": "Problem 1",
    "text": "Problem 1\nRecall the gamma function\n\\[\n\\Gamma(x)=\\int_0^\\infty y^{x-1}e^{-y}\\,\\text{d}y.\n\\]\nShow that \\(\\Gamma\\left(\\frac{1}{2}\\right)=\\sqrt{\\pi}\\).\n\n\n\n\n\n\nHint\n\n\n\n\n\nTwo things to remember, for this problem set, for the midterm, and for life in general:\n\nevery probability density function is a funky integral identity in disguise;\n“massage and squint.”",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-2",
    "href": "psets/pset_5.html#problem-2",
    "title": "Problem Set 5",
    "section": "Problem 2",
    "text": "Problem 2\nHere is the pdf of some absolutely continuous random variable:\n\\[\nf(x)=\\begin{cases}\nax^2e^{-bx^2} & x\\geq 0\\\\\n0 & x&lt; 0.\n\\end{cases}\n\\]\nSolve for \\(a\\) in terms of \\(b\\). So your final answer will look like\n\\[\na=\\text{``some formula including $b$ and a bunch of constants''}\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-3",
    "href": "psets/pset_5.html#problem-3",
    "title": "Problem Set 5",
    "section": "Problem 3",
    "text": "Problem 3\nLet \\(X\\) be a nonnegative, absolutely continuous random variable with density \\(f\\). Assuming \\(E(X)\\) is finite, show that\n\\[\nE(X)=\\int_0^\\infty P(X&gt;x)\\,\\text{d} x.\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nStart on the right-hand side and manipulate it until you get the left-hand side. There are several ways to do this: one for those of you that took multivariable calculus, and one for those who didn’t.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-4",
    "href": "psets/pset_5.html#problem-4",
    "title": "Problem Set 5",
    "section": "Problem 4",
    "text": "Problem 4\nLet \\(X\\) be a random variable with finite expectation, pdf \\(f(x)\\), and cdf \\(F(x)\\). Assuming \\(E(X)\\) is finite, show that\n\\[\nE(X)=\\int_0^1F^{-1}(x)\\,\\text{d} x.\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nIf you pick a good u-substitution, there’s almost no work here.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-5",
    "href": "psets/pset_5.html#problem-5",
    "title": "Problem Set 5",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(X\\) be any random variable whose moment-generating function exists, and define a new random variable \\(Y=aX+b\\) for arbitrary constants \\(a,\\,b\\in\\mathbb{R}\\). Show that\n\\[\nM_Y(t)=e^{bt}M_X(at).\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-6",
    "href": "psets/pset_5.html#problem-6",
    "title": "Problem Set 5",
    "section": "Problem 6",
    "text": "Problem 6\nConsider an absolutely continuous random variable \\(X\\) with pdf\n\\[\nf_X(x)=\\frac{e^{-\\frac{x-\\mu}{s}}}{s\\left[1+e^{-\\frac{x-\\mu}{s}}\\right]^2}\\quad x\\in\\mathbb{R},\n\\]\nwhere \\(\\mu\\in\\mathbb{R}\\) and \\(s&gt;0\\) are parameters.\n\nCompute the cdf of \\(X\\).\nCompute \\(E(X)\\).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWork smarter not harder. You have that \\(1/s\\) constant out front, and that \\((x-\\mu)/s\\) bit floating around. What does that tell you?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-7",
    "href": "psets/pset_5.html#problem-7",
    "title": "Problem Set 5",
    "section": "Problem 7",
    "text": "Problem 7\nConsider a random variable \\(X\\) with pdf\n\\[\nf(x;\\,\\theta) =\\begin{cases}\n\\frac{x}{\\theta}e^{-\\frac{x^2}{2\\theta}} & x\\geq 0\\\\\n0 & \\text{else},\n\\end{cases}\n\\]\nwhere \\(\\theta &gt;0\\) is a parameter.\n\nCompute the CDF of \\(X\\).\nCompute the median of \\(X\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-8",
    "href": "psets/pset_5.html#problem-8",
    "title": "Problem Set 5",
    "section": "Problem 8",
    "text": "Problem 8\nHere is the cdf of an absolutely continuous random variable \\(X\\):\n\\[\nF(x;\\,\\alpha,\\,\\theta)\n=\n\\begin{cases}\n1-\\left(\\frac{\\theta}{x + \\theta}\\right)^\\alpha & x &gt;0 \\\\\n0 & \\text{else}.\n\\end{cases}\n\\]\nThe parameters \\(\\alpha\\) and \\(\\theta\\) are just positive constants.\n\nFind the pdf of \\(X\\) and plot it for \\(\\alpha=1,\\, 2,\\, 3\\) and \\(\\theta = 1\\).\nCompute \\(E(X)\\). Is it finite for all values of the parameters?\nCompute \\(\\textrm{var}(X)\\). Is it finite for all values of the parameters?\nFix \\((\\alpha,\\,\\theta) = (3,\\, 100)\\) and compute \\(P(X &gt; 75\\,|\\, X &gt; 50)\\).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nProblems 3 and 4 at the top of this very problem set provide you with alternative methods for calculating expected values. See if you don’t find them useful here.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-9",
    "href": "psets/pset_5.html#problem-9",
    "title": "Problem Set 5",
    "section": "Problem 9",
    "text": "Problem 9\nLet \\(X\\) be absolutely continuous with density\n\\[\nf(x)=\\begin{cases}\n2x & 0&lt;x&lt;1\\\\\n0 & \\text{else}.\n\\end{cases}\n\\]\nFind the mgf of \\(X\\) and use it to compute the first two moments.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-10",
    "href": "psets/pset_5.html#problem-10",
    "title": "Problem Set 5",
    "section": "Problem 10",
    "text": "Problem 10\n\nCompute the moment generating function of the geometric distribution. For what values of \\(t\\) is it defined?\nUse the mgf to compute the mean and variance of the geometric distribution.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-11",
    "href": "psets/pset_5.html#problem-11",
    "title": "Problem Set 5",
    "section": "Problem 11",
    "text": "Problem 11\n\nLet \\(X\\sim\\text{Unif}(0,\\,1)\\), and find the density of \\(Y=e^X\\).\nLet \\(X\\sim\\textrm{Unif}(0,\\,1)\\), and find the density of \\(Y=\\sqrt{X}\\).\nLet \\(X\\sim\\textrm{N}(\\mu,\\,\\sigma^2)\\), and find the density of \\(Y=e^X\\)?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-12",
    "href": "psets/pset_5.html#problem-12",
    "title": "Problem Set 5",
    "section": "Problem 12",
    "text": "Problem 12\nLet \\(Z\\sim\\textrm{N}(0,\\,1)\\) and let \\(X\\sim\\textrm{N}(0,\\,\\sigma^2)\\).\n\nFind the pdf of \\(Y=|Z|\\).\nCompute \\(E(Y)\\).\nCompute \\(\\textrm{var}(Y)\\).\nFind the pdf of \\(W=|X|\\).\nCompute \\(E(W)\\) and \\(\\textrm{var}(W)\\).\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nIf you do parts a, b, and c correctly, and you understand how \\(Z\\) and \\(X\\) are related to one another, then you don’t necessarily have to do a lot of work on parts d and e.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-13",
    "href": "psets/pset_5.html#problem-13",
    "title": "Problem Set 5",
    "section": "Problem 13",
    "text": "Problem 13\nSuppose \\(X\\) and \\(Y\\) are jointly absolutely continuous random variables with joint density\n\\[\nf_{XY}(x,\\,y)=xe^{-x(y+1)},\\quad x,\\,y&gt;0.\n\\]\n\nFind the marginal density of \\(X\\).\nFind the marginal density of \\(Y\\).\nFind the conditional density of \\(X\\) given \\(Y=y\\).\nFind the conditional density of \\(Y\\) given \\(X=x\\).\nFind the density of \\(Z=XY\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-14",
    "href": "psets/pset_5.html#problem-14",
    "title": "Problem Set 5",
    "section": "Problem 14",
    "text": "Problem 14\n\\(X\\) and \\(Y\\) are jointly absolutely continuous with joint density\n\\[\nf_{XY}(x,\\, y)\n=\nc\n(y^2-x^2)\ne^{-y}\n,\\quad\ny&gt;0\n;\\,\n-y&lt;x&lt;y.\n\\]\n\nSketch \\(\\textrm{Range}(X,\\, Y)\\).\nCompute \\(c\\).\nCompute the marginal density of \\(X\\).\nCompute the marginal density of \\(Y\\).\nCompute \\(E(X)\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-15",
    "href": "psets/pset_5.html#problem-15",
    "title": "Problem Set 5",
    "section": "Problem 15",
    "text": "Problem 15\nLet \\(X\\) be an absolutely continuous random variable with the following:\n\\[\n\\begin{align*}\n    \\textrm{Range}(X)&=(0,\\, 1)\\\\\n    f_X(x)&=\\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}x^{a-1}(1-x)^{b-1},\n    \\quad 0&lt;x&lt;1.\n\\end{align*}\n\\]\nThis means \\(X\\) has the beta distribution, and we write \\(X\\sim\\textrm{Beta}(a,\\, b)\\). Now let \\(Y\\sim\\textrm{Gamma}(a+b,\\, c)\\) be independent of \\(X\\), and define a third random variable \\(Z=XY\\).\n\nWrite the joint distribution of \\(X\\) and \\(Z\\) in hierarchical form:\n\n\\[\n    \\begin{align*}\n        X &\\sim \\textrm{???}\\\\\n        Z\\,|\\, X = x &\\sim \\textrm{???}.\n    \\end{align*}\n\\]\n\nBased on this hierarchy, compute the marginal density of \\(Z\\). Is it familiar?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "psets/pset_5.html#problem-16",
    "href": "psets/pset_5.html#problem-16",
    "title": "Problem Set 5",
    "section": "Problem 16",
    "text": "Problem 16\nLet \\(X\\) and \\(Y\\) be jointly absolutely continuous with density\n\\[\nf_{XY}(x,\\, y)=\\frac{1}{\\pi},\\quad x^2+y^2\\leq 1.\n\\]\nSo \\(X\\) and \\(Y\\) jointly possess the uniform distribution on the unit disc.\n\nThe joint density is a surface in three-dimensional space. Sketch what the joint density looks like.\nCompute the marginal densities of \\(X\\) and \\(Y\\).\nAre \\(X\\) and \\(Y\\) independent?\nCompute \\(\\textrm{cov}(X,\\, Y)\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 5"
    ]
  },
  {
    "objectID": "labs/lab-7.html",
    "href": "labs/lab-7.html",
    "title": "Lab 7: risk and return",
    "section": "",
    "text": "My ventures are not in one bottom trusted,Nor to one place; nor is my whole estateUpon the fortune of this present year:Therefore my merchandise makes me not sad.\nThe Merchant of Venice\nMathematical finance is a major area of application for probability and statistics. When an individual or institution is deciding how best to invest their money, there are many competing options (stocks, bonds, real estate, etc), and they all bare some type of risk. The hope is that mathematical models can be used to manage this risk and guide investors in making optimal decisions in an environment of uncertainty.\nIn this lab, we will use tools from our course to study the portfolio selection problem. That is, given two competing assets, what fraction of my money should I invest in one, and what fraction should I invest in the other? Should I go 50/50? 60/40? 25/75? 100/0? The answer will hinge on two important points:",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-1",
    "href": "labs/lab-7.html#task-1",
    "title": "Lab 7: risk and return",
    "section": "Task 1",
    "text": "Task 1\nLet \\((X,\\,Y)\\) be jointly distributed and possibly dependent. If \\(a,\\,b\\in\\mathbb{R}\\) are constants, what is \\(E(aX+bY)\\)?",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-2",
    "href": "labs/lab-7.html#task-2",
    "title": "Lab 7: risk and return",
    "section": "Task 2",
    "text": "Task 2\nWhat is \\(\\text{var}(aX+bY)\\), again accounting for the possibility that \\(X\\) and \\(Y\\) are dependent?",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-3",
    "href": "labs/lab-7.html#task-3",
    "title": "Lab 7: risk and return",
    "section": "Task 3",
    "text": "Task 3\nAssume momentarily that \\(R_A\\) and \\(R_B\\) are independent and identically distributed (iid), implying that \\(E(R_A)=E(R_B)=\\mu\\), \\(\\text{var}(R_A)=\\text{var}(R_B)=\\sigma^2\\), and \\(\\text{cor}(R_A,\\,R_B) = 0\\).\nImagine two possible portfolios:\n\n\nPortfolio 1: invest equally in both assets;\n\nPortfolio 2: invest everything in \\(A\\) and none in \\(B\\).\n\nCompute the mean and variance of the return for each portfolio. Which portfolio would you prefer to hold, and why?\n\n\n\n\n\n\nWink wink nudge nudge\n\n\n\nIt might be good to include the word diversification in your answer.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-4",
    "href": "labs/lab-7.html#task-4",
    "title": "Lab 7: risk and return",
    "section": "Task 4",
    "text": "Task 4\nEvery weight \\(w\\in[0,\\,1]\\) corresponds to a different portfolio, and each portfolio will have a different mean and variance (ie return and risk) associated with it. To display the full menu of options, we can plot the so-called “Markowitz bullet:”\n\n\n\n\n\n\n\n\nEach point along this curve corresponds to a different \\(w\\) and its associated (risk, return) pair. The endpoints of the curve correspond to the portfolios that place all weight on either of the assets (\\(w=0\\) or \\(w=1\\)), and then you have all the combinations in between.\nWhat is this curve saying about diversification and the trade-off between risk and return? Where on the curve would you personally prefer to be?",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-5",
    "href": "labs/lab-7.html#task-5",
    "title": "Lab 7: risk and return",
    "section": "Task 5",
    "text": "Task 5\nFill in the blanks below to write a function in R that plots the bullet:\n\nmarkowitz_bullet &lt;- function(EA, EB, VA, VB, r){\n  w &lt;- seq(0, 1, length.out = 1000)\n  \n  BLANK \n  \n  plot( BLANK )\n}\n\nThe function will take five numbers as arguments: the means and variances of the two assets, as well as their correlation.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-6",
    "href": "labs/lab-7.html#task-6",
    "title": "Lab 7: risk and return",
    "section": "Task 6",
    "text": "Task 6\nPlay around with the function you wrote. Plot the bullet for different choices of means, variances, and correlations. Observe how these different settings change the shape of the curve, and write a sentence or two discussing the lesson for diversification, portfolio selection, navigating the trade-off between risk and return, whatever:\n\nif \\(R_A\\) and \\(R_B\\) are iid;\n\n\\(\\mu_A &gt; \\mu_B\\), \\(\\sigma_A = \\sigma_B\\), and \\(\\rho = 0\\);\n\n\\(\\mu_A &gt; \\mu_B\\), \\(\\sigma_A = \\sigma_B\\), and \\(\\rho = 0.5\\);\n\n\\(\\mu_A &gt; \\mu_B\\), \\(\\sigma_A = \\sigma_B\\), and \\(\\rho = 1\\);\n\n\\(\\mu_A &gt; \\mu_B\\), \\(\\sigma_A = \\sigma_B\\), and \\(\\rho = -0.5\\);\n\n\\(\\mu_A &gt; \\mu_B\\), \\(\\sigma_A = \\sigma_B\\), and \\(\\rho = -1\\);\n\n\\(\\mu_A &gt; \\mu_B\\) and \\(\\sigma_A = 0\\);\n\n\\(\\mu_A &gt; \\mu_B\\) and \\(\\sigma_B = 0\\).",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-7",
    "href": "labs/lab-7.html#task-7",
    "title": "Lab 7: risk and return",
    "section": "Task 7",
    "text": "Task 7\nAssume \\(R_A\\) and \\(R_B\\) are uncorrelated, and the variances could be anything. Solve for the value of \\(w\\) that minimizes \\(\\text{var}(R)\\).",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-7.html#task-infty",
    "href": "labs/lab-7.html#task-infty",
    "title": "Lab 7: risk and return",
    "section": "Task \\(\\infty\\)\n",
    "text": "Task \\(\\infty\\)\n\nThis toy model was enough for one lab, but it can be extended in several directions to make it more realistic:\n\nWe assumed only two assets, but the original 1952 paper by Harry Markowitz worked things out for a general set of \\(n\\) assets;\nWe performed a “mean-variance” analysis that ignored all features of the return distribution besides the first and second moment. But other features matter, like the skew (third moment). If the distribution of \\(R_A\\) is very left skewed (skewed toward the negative end where you lose money) compared to \\(R_B\\), that should surely affect the weight I place on that asset;\nWe assumed that the means and variances of asset returns were known, when in fact they are unknown and must be estimated from historical data, which is a major complication;\nWe assumed a static world where the distribution of returns is fixed and the consequences of our decisions cash out in a single period, but the world is dynamic and decisions but be sequentially re-optimized as the environment changes;\nWe assumed the portfolio weight \\(w\\) had to be in \\([0,\\,1]\\), but why? Ever heard of shorting?\n\nIf you take courses in mathematical finance, you’ll learn about all of these things and much more. And you’ll use a ton of probability and statistics along the way!",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab-4.html",
    "href": "labs/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "Here are the famous, “named” families of probability distributions we have seen so far:\n\n\n\n\n\n\n\n\n\ndistribution\nrange\npmf/pdf\nmean\nvariance\n\n\n\n\\(X\\sim\\text{Bern}(p)\\)\n\\(\\{0,\\,1\\}\\)\n\\(p^x(1-p)^{1-x}\\)\n\\(p\\)\n\\(p(1-p)\\)\n\n\n\\(X\\sim\\text{Binom}(n,\\,p)\\)\n\\(\\{0,\\,1,\\,2,\\,...,\\,n\\}\\)\n\\(\\binom{n}{x}p^x(1-p)^{n-x}\\)\n\\(np\\)\n\\(np(1-p)\\)\n\n\n\\(X\\sim\\text{Geom}(p)\\)\n\\(\\{1,\\,2,\\,3,\\,...\\}\\)\n\\((1-p)^{x-1}x\\)\n\\(1/p\\)\n\\(\\frac{1-p}{p^2}\\)\n\n\n\\(X\\sim\\text{Pois}(\\lambda)\\)\n\\(\\mathbb{N}\\)\n\\(e^{-\\lambda}\\frac{\\lambda^x}{x!}\\)\n\\(\\lambda\\)\n\\(\\lambda\\)\n\n\n\\(X\\sim\\text{N}(\\mu,\\,\\sigma^2)\\)\n\\(\\mathbb{R}\\)\n\\(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)\\)\n\\(\\mu\\)\n\\(\\sigma^2\\)\n\n\n\\(X\\sim\\text{Gamma}(\\alpha,\\,\\beta)\\)\n\\((0,\\,\\infty)\\)\n\\(\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha-1}e^{-\\beta x}\\)\n\\(\\alpha/\\beta\\)\n\\(\\alpha/\\beta^2\\)\n\n\n\nFor each distribution family, R provides four basic functions for working with it.\n\nThe cumulative distribution function (cdf) of a random variable \\(X\\) is the function \\(F:\\mathbb{R}\\to[0,\\,1]\\) that returns \\(F(x)=P(X\\leq x)\\) for any \\(x\\in\\mathbb{R}\\). Every distribution family has a p- function that evaluates the cdf:\n\n# discrete \n\npbinom(x, size, prob) # Bernoulli is just binomial with size = 1\npgeom(x, prob)\nppois(x, lambda)\n\n# continuous\n\npnorm(x, mean = 0, sd = 1)\npgamma(x, shape, rate = 1)\n\nSo if I call\n\npnorm(-2.4, 4, 3)\n\n[1] 0.0164487\n\n\nit returns \\(P(X\\leq -2.4)\\) for \\(X\\sim\\text{N}(4, 9)\\). If I want \\(P(-2.4 &lt; X &lt; 0.5)\\), then I know that \\(P(a&lt;X&lt;b)=F_X(b)-F_X(a)\\), so I can call\n\npnorm(0.5, 4, 3) - pnorm(-2.4, 4, 3)\n\n[1] 0.1052238\n\n\nRecall that for a continuous random variable, it doesn’t matter if I include the endpoints or not when calculating the probability of an interval, since \\(P(X=c)=0\\) for any \\(c\\in\\mathbb{R}\\). But this is not the case for a discrete random variable, so you have to be careful. If \\(Y\\sim\\text{Pois}(4)\\), and I want \\(P(2 &lt; Y &lt; 5)\\), it would not be correct to compute \\(F_Y(5) - F_Y(2)\\), because that will include \\(P(Y=5)&gt;0\\). The event \\(2 &lt; Y &lt; 5\\) is equivalent to \\(2 &lt; Y \\leq 4\\), and now I can compute:\n\nppois(4, 4) - ppois(2, 4)\n\n[1] 0.3907336\n\n\n\n\n\n\n\n\nThe normal commands take the standard deviation, not the variance!\n\n\n\nYou will get burned by this at least once. I guarantee it. But please take note. When I wanted \\(P(X\\leq -2.4)\\) for \\(X\\sim\\text{N}(4, 9)\\), I called pnorm(-2.4, 4, 3), because \\(\\text{sd}(X)=\\sqrt{\\text{var}(X)}=3\\).\n\n\n\nThese commands generate n random numbers that behave according to the distribution you specify:\n\n# discrete \n\nrbinom(n, size, prob)\nrgeom(n, prob)\nrpois(n, lambda)\n\n# continuous\n\nrnorm(n, mean = 0, sd = 1)\nrgamma(n, shape, rate = 1)\n\nFor example:\n\nrnorm(5, mean = 4, sd = 3)\n\n[1]  2.1613071  6.6467256 -0.6438999  3.6999242  2.4109673\n\n\n\nFor both discrete and (absolutely) continuous distributions, R uses the same syntax for evaluating the pmf/pdf:\n\n# discrete \n\ndbinom(x, size, prob)\ndgeom(x, prob)\ndpois(x, lambda)\n\n# continuous\n\ndnorm(x, mean = 0, sd = 1)\ndgamma(x, shape, rate = 1)\n\nThis is understandable but slightly unfortunate, because we know that the pmf is a function that returns probabilities when evaluated. The pdf is not. But anyway, if you want \\(P(X=5)\\) for \\(X\\sim\\text{Binom}(10, 0.3)\\), here you go:\n\ndbinom(5, 10, 0.3)\n\n[1] 0.1029193\n\n\nDo you understand what this command did?\n\ndbinom(0, 1, 0.7)\n\n[1] 0.3\n\n\n\nWe will not work with this today, but for completeness, the quantile function of a random variable is the (generalized) inverse of its cdf. So \\(F^{-1}\\). It is the function that, given a probability \\(\\alpha\\in(0,\\,1)\\), returns the cut-off point on the number line that has that much probability to the left. So the \\(\\alpha\\)th quantile \\(q_{\\alpha}\\) satisfies \\(P(X\\leq q_\\alpha) = \\alpha\\). Here is the picture:\n\n\n\n\nThe median is the \\(\\alpha=0.5\\) quantile. The quantiles of the standard normal distribution are famous:\n\nqnorm(0.95)\n\n[1] 1.644854\n\nqnorm(0.975)\n\n[1] 1.959964\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nEvery distribution family has a q- function that, given \\(p\\in(0,\\,1)\\), returns \\(q_p\\):\n\n# discrete \n\nqbinom(p, size, prob) # Bernoulli is just binomial with size = 1\nqgeom(p, prob)\nqpois(p, lambda)\n\n# continuous\n\nqnorm(p, mean = 0, sd = 1)\nqgamma(p, shape, rate = 1)\n\nThis is easier to understand for a random variable whose cdf is smooth and one-to-one. For discrete random variables, the behavior of the q- function is a bit subtle, and we’ll get into it later.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#p--functions-evaluating-the-cdf",
    "href": "labs/lab-4.html#p--functions-evaluating-the-cdf",
    "title": "Lab 4",
    "section": "",
    "text": "The cumulative distribution function (cdf) of a random variable \\(X\\) is the function \\(F:\\mathbb{R}\\to[0,\\,1]\\) that returns \\(F(x)=P(X\\leq x)\\) for any \\(x\\in\\mathbb{R}\\). Every distribution family has a p- function that evaluates the cdf:\n\n# discrete \n\npbinom(x, size, prob) # Bernoulli is just binomial with size = 1\npgeom(x, prob)\nppois(x, lambda)\n\n# continuous\n\npnorm(x, mean = 0, sd = 1)\npgamma(x, shape, rate = 1)\n\nSo if I call\n\npnorm(-2.4, 4, 3)\n\n[1] 0.0164487\n\n\nit returns \\(P(X\\leq -2.4)\\) for \\(X\\sim\\text{N}(4, 9)\\). If I want \\(P(-2.4 &lt; X &lt; 0.5)\\), then I know that \\(P(a&lt;X&lt;b)=F_X(b)-F_X(a)\\), so I can call\n\npnorm(0.5, 4, 3) - pnorm(-2.4, 4, 3)\n\n[1] 0.1052238\n\n\nRecall that for a continuous random variable, it doesn’t matter if I include the endpoints or not when calculating the probability of an interval, since \\(P(X=c)=0\\) for any \\(c\\in\\mathbb{R}\\). But this is not the case for a discrete random variable, so you have to be careful. If \\(Y\\sim\\text{Pois}(4)\\), and I want \\(P(2 &lt; Y &lt; 5)\\), it would not be correct to compute \\(F_Y(5) - F_Y(2)\\), because that will include \\(P(Y=5)&gt;0\\). The event \\(2 &lt; Y &lt; 5\\) is equivalent to \\(2 &lt; Y \\leq 4\\), and now I can compute:\n\nppois(4, 4) - ppois(2, 4)\n\n[1] 0.3907336\n\n\n\n\n\n\n\n\nThe normal commands take the standard deviation, not the variance!\n\n\n\nYou will get burned by this at least once. I guarantee it. But please take note. When I wanted \\(P(X\\leq -2.4)\\) for \\(X\\sim\\text{N}(4, 9)\\), I called pnorm(-2.4, 4, 3), because \\(\\text{sd}(X)=\\sqrt{\\text{var}(X)}=3\\).",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#r--functions-generating-random-numbers",
    "href": "labs/lab-4.html#r--functions-generating-random-numbers",
    "title": "Lab 4",
    "section": "",
    "text": "These commands generate n random numbers that behave according to the distribution you specify:\n\n# discrete \n\nrbinom(n, size, prob)\nrgeom(n, prob)\nrpois(n, lambda)\n\n# continuous\n\nrnorm(n, mean = 0, sd = 1)\nrgamma(n, shape, rate = 1)\n\nFor example:\n\nrnorm(5, mean = 4, sd = 3)\n\n[1]  2.1613071  6.6467256 -0.6438999  3.6999242  2.4109673",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#d--functions-evaluating-the-pmfpdf",
    "href": "labs/lab-4.html#d--functions-evaluating-the-pmfpdf",
    "title": "Lab 4",
    "section": "",
    "text": "For both discrete and (absolutely) continuous distributions, R uses the same syntax for evaluating the pmf/pdf:\n\n# discrete \n\ndbinom(x, size, prob)\ndgeom(x, prob)\ndpois(x, lambda)\n\n# continuous\n\ndnorm(x, mean = 0, sd = 1)\ndgamma(x, shape, rate = 1)\n\nThis is understandable but slightly unfortunate, because we know that the pmf is a function that returns probabilities when evaluated. The pdf is not. But anyway, if you want \\(P(X=5)\\) for \\(X\\sim\\text{Binom}(10, 0.3)\\), here you go:\n\ndbinom(5, 10, 0.3)\n\n[1] 0.1029193\n\n\nDo you understand what this command did?\n\ndbinom(0, 1, 0.7)\n\n[1] 0.3",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#q--functions-evaluating-the-quantile-function",
    "href": "labs/lab-4.html#q--functions-evaluating-the-quantile-function",
    "title": "Lab 4",
    "section": "",
    "text": "We will not work with this today, but for completeness, the quantile function of a random variable is the (generalized) inverse of its cdf. So \\(F^{-1}\\). It is the function that, given a probability \\(\\alpha\\in(0,\\,1)\\), returns the cut-off point on the number line that has that much probability to the left. So the \\(\\alpha\\)th quantile \\(q_{\\alpha}\\) satisfies \\(P(X\\leq q_\\alpha) = \\alpha\\). Here is the picture:\n\n\n\n\nThe median is the \\(\\alpha=0.5\\) quantile. The quantiles of the standard normal distribution are famous:\n\nqnorm(0.95)\n\n[1] 1.644854\n\nqnorm(0.975)\n\n[1] 1.959964\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nEvery distribution family has a q- function that, given \\(p\\in(0,\\,1)\\), returns \\(q_p\\):\n\n# discrete \n\nqbinom(p, size, prob) # Bernoulli is just binomial with size = 1\nqgeom(p, prob)\nqpois(p, lambda)\n\n# continuous\n\nqnorm(p, mean = 0, sd = 1)\nqgamma(p, shape, rate = 1)\n\nThis is easier to understand for a random variable whose cdf is smooth and one-to-one. For discrete random variables, the behavior of the q- function is a bit subtle, and we’ll get into it later.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#the-number-of-claims",
    "href": "labs/lab-4.html#the-number-of-claims",
    "title": "Lab 4",
    "section": "The number of claims",
    "text": "The number of claims\nThe random variable \\(N\\) is discrete. It’s counting the number of claims received in a month.\nTask 8\nSay that \\(N\\) follows a Poisson distribution. The actuaries at Pacific All-Risk know that historically, the company typically receives about 100 claims per month. To capture this, how should we set the parameter(s) of the Poisson distribution?\nTask 9\nWhat is the probability that \\(N\\) is strictly within one standard deviation of its mean? In other words, what is the probability that \\(N\\) lies in the interval \\((E(N)-\\text{sd}(N),\\,E(N)+\\text{sd}(N))\\). Use the appropriate p- function to compute this, and pay attention to the endpoints!\nTask 10\nWhat is the probability that \\(N\\) is at or above its mean? So, \\(P(N\\geq E(N))\\)?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#the-size-of-a-claim",
    "href": "labs/lab-4.html#the-size-of-a-claim",
    "title": "Lab 4",
    "section": "The size of a claim",
    "text": "The size of a claim\nLet \\(X\\) be the size of a single claim the company receives. \\(X\\) is measured in units of dollars and cents, so it is most appropriate to model \\(X\\) as a continuous random variable that only takes on positive values.\n\n\n\n\n\n\nDon’t read this\n\n\n\n\n\nOne could argue that all random variables are discrete in practice. In financial markets for instance, there is a minimum tick size (you can’t quote a price of $1.0000000001), and so prices fluctuate on a discrete grid. Or in general, we only ever work with numbers represented on a computer, and a computer can only store a finite number of decimals. In these cases then, assuming a continuous distribution serves to clean up life.\n\n\n\nTask 11\nThe actuaries know that historically, claims are about $10,000 on average, with a standard deviation of $2,000. If we want to use the model \\(X\\sim\\text{Gamma}(\\alpha,\\,\\beta)\\), how should we set \\(\\alpha\\) and \\(\\beta\\) so that \\(X\\) has the correct location and spread?\nTask 12\nSimulate n = 5000 random numbers from the gamma distribution. Plot a histogram of these numbers, and overlay a line plot of the density.\nTask 13\nVerify that the sample mean and sample variance of your random numbers are close to the prescriptions from Task 11. If they are not, revisit Task 11 and adjust your choice of \\(\\alpha\\) and \\(\\beta\\) until this works.\nTask 14\nWhat is the probability \\(P(X &gt; 15,000)\\)? Calculate this probability exactly using the appropriate p- function, and also approximate it using your random numbers. Verify that the two numbers are close.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-4.html#the-bottom-line",
    "href": "labs/lab-4.html#the-bottom-line",
    "title": "Lab 4",
    "section": "The bottom line",
    "text": "The bottom line\nThe number that the insurance company truly cares about is \\(S=X_1+X_2+...+X_N\\), the total amount of money they are on the hook for that month. \\(S\\) is a random variable, and it inherits its randomness both from \\(N\\) and from each \\(X_i\\). To keep things simple, we will assume that \\(N\\) and the \\(X_i\\) are independent, meaning their outcomes don’t influence one another. This is mathematically convenient, but it’s a lousy assumption in terms of realism. Are all of the insurance claims coming out of southern California recently totally unrelated to one another? I think not. But we don’t yet possess the tools to handle this, so we assume independence.\nTask 15\nWrite a function that simulates \\(S\\). So your function should spit out a single number, generated in the following way:\n\nSimulate \\(N\\);\nGiven the result of Step 1, simulate independent \\(X_1\\), \\(X_2\\), …, \\(X_N\\);\nGiven the result of Step 2, return \\(S=X_1+X_2+...+X_N\\).\nTask 16\nUsing the function you wrote in the previous task, simulate \\(n=5000\\) possible values for the random variable \\(S\\) and plot a histogram of them.\nTask 17\nUse your simulations to approximate the probability \\(P(S&gt;1,300,00)\\).\nTask 18\nCompute the sample mean and the sample variance of your simulations. Based on these, can you conjecture how the parameters of the underlying \\(\\text{Poisson}(\\lambda)\\) and \\(\\text{Gamma}(\\alpha,\\,\\beta)\\) distributions are related to \\(E(S)\\) and \\(\\text{var}(S)\\)? That is, propose formulas \\(E(S)=h(\\lambda,\\,\\alpha,\\,\\beta)\\) and \\(\\text{var}(S)=g(\\lambda,\\,\\alpha,\\,\\beta)\\) that describe how the underlying Poisson and gamma parameters determine the moments of \\(S\\).",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab-3.html",
    "href": "labs/lab-3.html",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "",
    "text": "A vector in R is just an ordered set of values. The easiest way to create one is to manually list out the values, separated by commas, inside c():\n\nmyvec &lt;- c(pi, 5, 3.6, 2, 9, 6000) \nmyvec\n\n[1]    3.141593    5.000000    3.600000    2.000000    9.000000 6000.000000\n\n\nIf you want to list out all of the integers between some min and max, you can use this shortcut:\n\n5:15\n\n [1]  5  6  7  8  9 10 11 12 13 14 15\n\n\nMore generally, if you want a vector of evenly spaced numbers between a min and a max, do this:\n\na &lt;- seq(0, 1, length.out = 11) \na\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\n\nIf you want to create a “blank” vector that just has zeros in it, here you go:\n\nz &lt;- numeric(10)\nz\n\n [1] 0 0 0 0 0 0 0 0 0 0\n\n\nIn all of those cases, our vector contained numbers, but there is nothing special about numbers. Here is a vector where each value is a string (a piece of text):\n\npoetry &lt;- c(\"Mary\", \"had\", \"a\", \"little\", \"chainsaw\")\npoetry\n\n[1] \"Mary\"     \"had\"      \"a\"        \"little\"   \"chainsaw\"\n\n\nIn Lab 1 you learned about the sample command. This can be used to simulate a random phenomenon with a finite sample space. To simulate five flips of a fair coin:\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE)\n\n[1] \"T\" \"T\" \"H\" \"H\" \"T\"\n\n\nThe vector c(\"H\", \"T\") represents the sample space, size = 5 is the number of simulations you want to perform, and replace = TRUE ensures that you are repeating the trial from scratch each time. By default, sample assumes that all outcomes are equally likely. To override this, you can supply a vector of probabilities:\n\nsample(x = c(\"H\", \"T\"), size = 5, replace = TRUE, prob = c(0.8, 0.2))\n\n[1] \"H\" \"H\" \"H\" \"H\" \"H\"\n\n\nYou see that the vector is the same length as the sample space (so every outcome gets its own individual probability), and the probabilities have to sum to one.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-1",
    "href": "labs/lab-3.html#task-1",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 1",
    "text": "Task 1\nWe have provided you with a pre-trained language model kn, a vector midsummer_words containing the 3,063 unique words in the play, and a function next_word_probs:\n\ncond_dist &lt;- next_word_probs(context, midsummer_words, kn)\ntail(cond_dist)\n\n         words         prob\n3058  unearned 3.375323e-05\n3059    'scape 3.375323e-05\n3060 serpent's 3.375323e-05\n3061    amends 6.751470e-05\n3062      liar 3.375323e-05\n3063   restore 3.375323e-05\n\n\nSo, given the context, the set of possible words, and the model, it returns a table (a data frame) listing out all the words together with their conditional probabilities given the context.\nRun this function and use the output together with the sample function to simulate a new word.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-2",
    "href": "labs/lab-3.html#task-2",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 2",
    "text": "Task 2\nUse the paste function to append the word you simulated in Task 1 to the end of context. Then, starting from this updated context, go back to the beginning, generate a new conditional distribution, and use it to simulate a new word.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-3",
    "href": "labs/lab-3.html#task-3",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 3",
    "text": "Task 3\nWrite a for loop that iterates the process in Tasks 1 and 2 in order to add six new words to the context.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-4",
    "href": "labs/lab-3.html#task-4",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 4",
    "text": "Task 4\nRerun your code ten times to generate ten different responses. How many of them would you consider basically coherent?",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-5",
    "href": "labs/lab-3.html#task-5",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 5",
    "text": "Task 5\nNow that you have the basic code, play around with different starting contexts besides “now fair hippolyta.” Bear in mind that our world is small here. We’ve trained the model on a single, old text, so if you want coherent responses, you should probably give it something in the ballpark of what it has seen before. I doubt “which banger slaps hardest my dude” will yield anything meaningful (though feel free to try!). For inspiration, here is the full text of the original play.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-6",
    "href": "labs/lab-3.html#task-6",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 6",
    "text": "Task 6\nUp to now we’ve been worrying a lot about individual words, but individual words don’t create meaning. It’s how those words interact across phrases and sentences and paragraphs. Unfortunately, we do not have methods for inducing a probability distribution over the set of all possible sentences, or the set of all possible thoughts. But in a sense, language models are attempting to approximate such a thing. And on the evidence to date, maybe they succeed sometimes. Anyway, how do we go from a method that gets things right on the word level to a method that gets things right on the sentence level? Well, therein lies the art of the engineers that work on these things, and one method they have found helpful is called temperature sampling.\nSo far, given the current context, the model returns a (conditional) probability \\(p(i)\\) for each word \\(i\\in \\text{corpus}\\). So far we’ve used these probabilities unmodified. With temperature sampling, before we draw the next word, we would first adjust the probabilities based on a user-defined tuning parameter \\(t&gt;0\\) called the temperature:\n\\[\np_t(i) = \\frac{e^{\\ln\\frac{p(i)}{t}}}{\\sum\\limits_{i\\in\\text{corpus}}e^{\\ln\\frac{p(i)}{t}}},\\quad i\\in\\text{corpus}.\n\\]\nIf \\(t=1\\), we’re back to the original probabilities (check this!). Otherwise, to quote the \\(k\\)-grams people, “higher and lower temperatures make the original probability distribution smoother and rougher, respectively. By making a physical analogy, we can think of less probable words as states with higher energies, and the effect of higher (lower) temperatures is to make more (less) likely to excite these high energy states.” Why do people do this? To the best of my knowledge, it is no deeper than “it seems to work well.” In practice, adjusting the temperature seems to have a macro effect on the overall character of the sentences.\nThe function next_word_probs that we gave you has a fourth argument temp where you can give it a number and it will give you the tempered probabilities. Play around with big and small values, and report any effect that it has on the overall quality of the sentences.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-3.html#task-7",
    "href": "labs/lab-3.html#task-7",
    "title": "Lab 3 - How does ChatGPT generate the next word?",
    "section": "Task 7",
    "text": "Task 7\nCode temperature sampling yourself. Take the probabilities that probs &lt;- next_word_probs(...) gives you when temp = 1.0, and then use basic R commands like exp, log, etc to apply the formula above and compute a vector temp_probs with the revised numbers for temp = 0.5. Check that your numbers agree with the ones that our function next_word_probs gives when you supply 0.5 as the fourth argument.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab-8.html",
    "href": "labs/lab-8.html",
    "title": "Lab 8",
    "section": "",
    "text": "Thursday April 17 is our last lab, and to celebrate, we will do something fun and silly. In order for this to go smoothly, please download the following programs onto your personal computer if you have not already done do:\n\nR: https://cran.rstudio.com/\nRStudio: https://posit.co/download/rstudio-desktop/\n\nMuseScore Studio: https://musescore.org/en\n\nselect Download Download MuseScore Studio without MuseHub.\n\n\n\nOnce you have downloaded these things, open RStudio, and install the gm package:\n\ninstall.packages(\"gm\")\n\nOnce you have done all of those things, copy this code into the console and try to run it:\n\nlibrary(gm)\n\nmusic &lt;- \n  Music() +\n  Meter(4, 4) +\n  Line(c(\"C5\", \"D5\", \"E5\", \"F5\"))\n  \nshow(music)\n\nIf everything went according to plan, the Viewer pane in the lower right will be launched, and inside you’ll see the following:\n\n\n\n\n\n\nDesired output\n\n\n\n\n\n\n\n\n\n\n\nIf that worked, you’re all set! Sit tight until next week.",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#task-1",
    "href": "labs/lab-8.html#task-1",
    "title": "Lab 8",
    "section": "Task 1",
    "text": "Task 1\nPretend that we know for a fact that \\(p_0 = 0.4\\).\n\nUse rbinom to simulate \\(n=10\\) realizations from Bern(0.4) and store them in a vector.\nCompute \\(\\hat{p}_n\\) for your simulated data.\nCompute a 90% confidence for your simulated data (remember qnorm?).\nIs the true value \\(p_0 = 0.4\\) in the interval you just computed?\nWhat is the probability that the true value is in the interval you just computed?\n\n\n\n\n\n\n\nWhat are we driving at?\n\n\n\n\n\nOne dataset, one point estimate, one interval. That’s all you’re going to have in practice. And that interval you computed for your data is either going to contain the true value or it’s not, with probability 100% or 0%, whatever the case may be. So the “90%” statement is not referring to the one-shot reliability of a particular realization of the interval on a single dataset. It is referring to the reliability of the interval method across datasets. So the sampling variability of the interval.",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#task-2",
    "href": "labs/lab-8.html#task-2",
    "title": "Lab 8",
    "section": "Task 2",
    "text": "Task 2\nOne of the main ideas in classical statistics is sampling variability. We model data as a random sample from an unknown distribution. Different random samples will give different point and interval estimates. So the point and interval estimates are themselves random quantities, and we can itemize their performance and reliability by studying their sampling distribution and seeing how the estimates vary across datasets. If they vary a little, we are comforted. If they vary a lot, we are troubled.\n\nFill in this function:\n\n\nsampling_distribution &lt;- function(p0, n, M){\n  # p0: the true probability of success\n  # n: the sample size of each iid dataset from Bern(p0)\n  # M: the number of alternative datasets to generate\n}\n\nInside, you should have a for loop. The loop cycles through \\(M\\) iterations, each time simulating a data set of size \\(n\\) from Bern(p0). For each of those datasets, compute the sample proportion of ones (“successes”) in that dataset. At the end, you will have a collection of \\(M\\) estimates. So, \\(M\\) realizations of \\(\\hat{p}_n\\). Plot a histogram of them: I like breaks = \"Scott\" as you know, make sure it’s a density histogram, and fix the range of the horizontal axis to xlim = c(0, 1).\n\n\nPlay around with your function. Adjust p0 and n and see what happens to the picture. In particular, convince yourself of these facts we have proven:\n\nthe sampling distribution is centered on the true value;\nthe sampling distribution’s spread (variance) shrinks as the sample size grows;\nthe shape of the sampling distribution resembles a bell curve for large \\(n\\);\n\n\nHere’s something true that we haven’t proven. The convergence of the sampling distribution to the normal is faster when the underlying distribution of the data is symmetric, and slower when the underlying distribution is highly skewed (this is a consequence of the Berry-Esseen theorem). What does that mean in this case? Can you use your function to illustrate that?",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-8.html#task-3",
    "href": "labs/lab-8.html#task-3",
    "title": "Lab 8",
    "section": "Task 3",
    "text": "Task 3\nYou just simulated the sampling distribution of the sample proportion. Now let’s think about the sampling distribution of the confidence interval. When you repeatedly sample new datasets and compute a new confidence interval for each one, what fraction of those intervals contain the true value?\n\nFill in this function. It will be similar to your function in the previous task, but in each iteration of the loop, compute a confidence interval for that dataset, and check if the true value (whatever you chose for p0) is included in the interval. After the loop is done, tally up the fraction of your \\(M\\) intervals that contained the true value.\n\n\ninterval_coverage &lt;- function(p0, n, M, alpha){\n  # p0: the true probability of success\n  # n: the sample size of each iid dataset from Bern(p0)\n  # M: the number of alternative datasets to generate\n  # alpha: confidence level of the interval\n}\n\nHere is a schematic of what you’re implementing: \\[\n\\underbrace{\n\\begin{matrix}\n  &&\\textrm{Bern}(p_0)&\\\\\n  &&&&\\\\\n  \\swarrow & \\swarrow & \\cdots & \\searrow &\\searrow \\\\[0.25cm]\n  x^{(1)}_1  & x^{(2)}_1  &        & x^{(M-1)}_1 & x^{(M)}_1\\\\[0.25cm]\n  x^{(1)}_2  & x^{(2)}_2  &        & x^{(M-1)}_2 & x^{(M)}_2\\\\[0.25cm]\n  \\vdots     & \\vdots     & \\cdots & \\vdots & \\vdots       \\\\[0.25cm]\n  x^{(1)}_{n}  & x^{(2)}_{n}  &        & x^{(M-1)}_n & x^{(M)}_{n}\\\\[0.25cm]\n  \\Big\\downarrow & \\Big\\downarrow &        & \\Big\\downarrow & \\Big\\downarrow \\\\[0.25cm]\n  (L_n^{(1)},\\,U_n^{(1)}) & (L_n^{(2)},\\,U_n^{(2)}) & \\cdots & (L_n^{(M-1)},\\,U_n^{(M-1)}) & (L_n^{(M)},\\,U_n^{(M)})\\\\\n  &&&&\\\\\n\\end{matrix}\n}_{\\text{What fraction of these intervals contain the true value of $p_0$? It had better be $\\approx1-\\alpha$!}}\n\\]\n\nIf \\(n\\) is large, your function had better spit out a number close to \\(1-\\alpha\\). But if \\(n\\) is moderate or small, it may not. And as we saw in the previous task, you might have a harder time achieving the prescribed coverage if \\(p_0=0.001\\) versus if \\(p_0=0.4\\). Use your function to illustrate these points. Consider this sequence of sample sizes: \\[\nn = 10,\\, 30,\\, 50,\\, 100,\\, 150,\\, 200,\\, 250.\n\\] Apply your function to each sample size. Use \\(\\alpha = 0.05\\). Create a line plot with sample size on the x-axis and the coverage of the confidence interval on the y-axis. Do this twice: once for \\(p_0=0.1\\) and again for \\(p_0=0.5\\).\n\n\n\n\n\n\n\nWhat are we driving at?\n\n\n\n\n\nAs \\(n\\) increases, you should see the interval coverage creep up to 95%. When \\(p_0=0.5\\), this will happen pretty much immediately. When \\(p_0=0.1\\), it will take a minute to get going.",
    "crumbs": [
      "Labs",
      "Lab 8"
    ]
  },
  {
    "objectID": "labs/lab-2.html",
    "href": "labs/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "Car Talk (1977 - 2012) was a popular show on NPR. It featured a segment called the “Puzzler,” where the hosts would read a brain teaser and invite listeners to send in solutions for the chance to win a prize. Here is the text of one such Puzzler (original audio at around 19:19 here):\nIn what follows, you may find some notation useful. Let \\(D\\) denote your true disease status, and \\(T\\) denote the result of your test. Then\n\\[\n\\begin{align*}\n    p &= P(D=+) && \\text{(prevalence)}\n    \\\\\n    f_{-}&=P(T=-\\,|\\, D=+) && \\text{(false negative rate)}\n    \\\\\n    f_{+}&=P(T=+\\,|\\, D=-) && \\text{(false positive rate)}\n    \\\\\n    1-f_{-}&=P(T=+\\,|\\, D = +) && \\text{(sensitivity)}\n    \\\\\n    1-f_{+}&=P(T=-\\,|\\, D = -) && \\text{(specificity)}.\n\\end{align*}\n\\]",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-1",
    "href": "labs/lab-2.html#problem-1",
    "title": "Lab 2",
    "section": "Problem 1",
    "text": "Problem 1\nWhat is your solution to the puzzler?",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-2",
    "href": "labs/lab-2.html#problem-2",
    "title": "Lab 2",
    "section": "Problem 2",
    "text": "Problem 2\nExplain the correct way to solve this problem. Exactly what probability are we asked to compute, and what formula should we apply to do it? Does the prompt actually provide enough information to ultimately get the job done?",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-3",
    "href": "labs/lab-2.html#problem-3",
    "title": "Lab 2",
    "section": "Problem 3",
    "text": "Problem 3\nThis is the solution that the hosts ultimately revealed (original audio at around 20:30 here):\n\nLet’s say 1000 people take the test. Fifty people will test positive and yet they will not have it. One will test positive and have it. So your chances of actually having it, even though you tested positive, are one in 51, or a little less than 2%.\n\nSo, what do you think? Did they get it right? Explain how the show interpreted the information given in the Puzzler, and explain what arithmetic formula they implicitly applied in order to compute their answer.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-4",
    "href": "labs/lab-2.html#problem-4",
    "title": "Lab 2",
    "section": "Problem 4",
    "text": "Problem 4\nExplain two things:\n\nUnder what conditions is the formula that the show used actually an upper bound on the correct answer?\nWhy might an upper bound on the true probability still be a useful thing to calculate?",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-5",
    "href": "labs/lab-2.html#problem-5",
    "title": "Lab 2",
    "section": "Problem 5",
    "text": "Problem 5\nSo, the show’s answer, while wrong, could still be potentially useful upper bound on the true probability. Neat! But how wrong is it, even? To get a sense of this, use a computer to create some line plots of the prevalence \\(p\\in[0,\\, 1]\\) against the true and approximate probabilities for different values of \\(f_-\\) and \\(f_+\\). Mix-and-match \\(f_-,\\, f_+\\in\\{0.1,\\, 0.2\\}\\).",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-2.html#problem-6",
    "href": "labs/lab-2.html#problem-6",
    "title": "Lab 2",
    "section": "Problem 6",
    "text": "Problem 6\nNow let’s try to be more precise about the “wrongness” of the show’s answer. Let \\(B\\) denote the true probability, and \\(\\overline{B}\\) denote the show’s approximation. In part (c) you showed that \\(B\\leq \\overline{B}\\) under certain conditions. Now define\n\\[\n\\delta = \\frac{\\overline{B}-B}{B}.\n\\]\nThis is the relative error of the show’s answer. Prove that\n\\[\n|\\delta|\n\\leq\n\\max\n\\left\\{\n\\frac{f_-}{1-f_-}\n,\\,\n\\frac{f_+}{1+f_+}\n\\right\\}\n,\\quad \\forall p\\in[0,\\, 1].\n\\]\nInterpret this result.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab-1.html",
    "href": "labs/lab-1.html",
    "title": "Lab 1",
    "section": "",
    "text": "Throughout this course, it may serve you well to familiarize yourself with the following:\n\n\nR/RStudio for coding;\n\nLaTeX (or \\(\\LaTeX\\), if you’re cool) for typesetting math;\n\nQuarto for synthesizing your expertly written code and your beautifully typeset math in a wonderfully legible PDF format!\n\nOf these three tools, we will focus the most on R/RStudio during lab time, though LaTeX and Quarto will certainly make incidental appearances.\nTo use R/RStudio, you can either use the Duke Container Manager or download the necessary applications here. Note: The R/RStudio in the containers comes with TinyTeX already downloaded. So, if you download the application and want to use LaTeX in your files, run the following command (and whatever subsequent commands you are prompted to run):\n\ntinytex::install_tinytex()\n\nFor a quick guide to useful LaTeX symbols, check out this OEIS wiki or this Rice page.\nTo learn more about Quarto, visit https://quarto.org.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#important-techno-babble",
    "href": "labs/lab-1.html#important-techno-babble",
    "title": "Lab 1",
    "section": "",
    "text": "Throughout this course, it may serve you well to familiarize yourself with the following:\n\n\nR/RStudio for coding;\n\nLaTeX (or \\(\\LaTeX\\), if you’re cool) for typesetting math;\n\nQuarto for synthesizing your expertly written code and your beautifully typeset math in a wonderfully legible PDF format!\n\nOf these three tools, we will focus the most on R/RStudio during lab time, though LaTeX and Quarto will certainly make incidental appearances.\nTo use R/RStudio, you can either use the Duke Container Manager or download the necessary applications here. Note: The R/RStudio in the containers comes with TinyTeX already downloaded. So, if you download the application and want to use LaTeX in your files, run the following command (and whatever subsequent commands you are prompted to run):\n\ntinytex::install_tinytex()\n\nFor a quick guide to useful LaTeX symbols, check out this OEIS wiki or this Rice page.\nTo learn more about Quarto, visit https://quarto.org.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#skillz",
    "href": "labs/lab-1.html#skillz",
    "title": "Lab 1",
    "section": "Skillz",
    "text": "Skillz\nBesides helping you exercise your probability and statistics muscles, each lab will help you develop your understanding of and comfort with various coding concepts and skills. Although the implementation will vary from language to language, the underlying structure will remain the same!\nThis lab exercises the following coding concepts:\n\nVectors/Arrays of numbers and strings;\n\nfor-loops;\nBoolean logic and operations;\nBase R functions like mean() and sample().",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#how-does-one-count-i-do-it.",
    "href": "labs/lab-1.html#how-does-one-count-i-do-it.",
    "title": "Lab 1",
    "section": "How does one count? (I do it.)",
    "text": "How does one count? (I do it.)\nCoin Toss\nWe first consider the flip of a fair coin. That is, when flipped, the coin will equiprobably come up heads or tails. Suppose we try to illustrate the fairness of a coin by physically flipping it a bunch of times. Very quickly, this becomes tedious and labor-intensive; surely, no reasonable/sane person would want to do this by hand…\n(Though, on the off chance that somebody actually did this, at least you might get co-authorship and recognition from various sectors of media.)\nAt any rate, R provides a much more enticing, efficient alternative to being one of about \\(50\\) people flipping coins thousands of times.\nFirst, let’s define a vector with the sample space – all possible outcomes – of a single coin flip. We notate heads as H and tails as T, and we call the vector sides_of_coin.\n\nsides_of_coin &lt;- c(\"H\", \"T\")\n\nTo simulate an actual coin flip, R has this nifty built-in function called sample().\nThe sample() function\nThe sample() function can take many arguments: a vector of elements (the sample space), a positive integer (the size), a Boolean (with or without replacement), and a vector of probabilities. So, a call to sample() will return a random sample of the specified size from the sample space, either with or without replacement, according to the vector of probabilities.\nNOTE: The replace Boolean defaults to FALSE (without replacement), and the prob vector defaults to equal weighting among the elements in the sample space.\nSample flips\nWe can perform a single coin flip with the following function call.\n\nsample(sides_of_coin, 1)\n\n[1] \"H\"\n\n\nIf we wanted to simulate multiple coin flips in the same vector, sample() lets us do that as well! Below is an example of a simulation of \\(10\\) coin flips.\n\nsample(sides_of_coin, 10, replace = TRUE)\n\n [1] \"H\" \"H\" \"H\" \"T\" \"H\" \"T\" \"H\" \"T\" \"H\" \"T\"\n\n\nWe can also use a different tool to simulate multiple fair coin flips: a for-loop.\n\nfor-loops\nA for-loop is a great way to perform the same set of commands a fixed, known number of times or to perform the same set of commands on the different elements in a vector. The bare bones of the for-loop are given below.\n\nfor(){\n  \n}\n\nIn the parentheses (), you define the variable and values of iteration; in the brackets {}, you list the commands to be performed in each iteration.\nSimulating the flips\nWe will simulation \\(5,000\\) independent flips of a fair coin and track whether each flip came up heads. We do this by initializing a \\(5,000\\)-element vector of zeroes and replacing each zero with a TRUE or FALSE according to the result of the current coin flip. You may find the corresponding code below.\n\nn_reps &lt;- 5000\nwas_it_heads &lt;- numeric(n_reps)\nfor(m in 1:n_reps){\n  new_flip &lt;- sample(sides_of_coin, 1)\n  was_it_heads[m] &lt;- new_flip == \"H\"\n}\n\nTo calculate the empirical probability of the coin coming up heads, we will calculate the proportion of flips in our simulation that came up heads. To do this, we can use either the mean() or sum() function; while those functions are typically used to average or sum vectors of numbers, they can also be used on Boolean vectors like was_it_heads. It will treat each TRUE as a one and each FALSE as a zero in the calculation.\nWe use each function in the code chunk below, remembering to divide the sum() call by the number of flips n_rep.\n\ncoin_prob &lt;- mean(was_it_heads)\ncoin_prob\n\n[1] 0.4914\n\nsum(was_it_heads) / n_reps\n\n[1] 0.4914\n\n\nAs expected, we see a proportion rather close to \\(0.5\\)! Due to the randomness of the individual flips and the finite number of flips, you likely won’t observe a proportion exactly equal to \\(0.5\\). However, the closeness of the proportion to the true probability is an illustration of the frequentist phenomenon of the long-run average. If you play around with the number of flips, you’ll tend to see that the longer the run, the closer the proportion to the true probability.\nFive-Card Poker Hand\nSuppose you are playing some sort of card game with a standard \\(52\\)-card deck. As part of this game, you are dealt a hand of five cards, the composition of which has some bearing on your success in the game.\nProvided is a vector representing the deck of cards, aptly (in my humble opinion) called deck_of_cards.\n\ndeck_of_cards &lt;- c(\"AH\", \"2H\", \"3H\", \"4H\", \"5H\", \"6H\", \"7H\", \"8H\", \"9H\", \"10H\", \"JH\", \"QH\", \"KH\", \"AD\", \"2D\", \"3D\", \"4D\", \"5D\", \"6D\", \"7D\", \"8D\", \"9D\", \"10D\", \"JD\", \"QD\", \"KD\", \"AC\", \"2C\", \"3C\", \"4C\", \"5C\", \"6C\", \"7C\", \"8C\", \"9C\", \"10C\", \"JC\", \"QC\", \"KC\", \"AS\", \"2S\", \"3S\", \"4S\", \"5S\", \"6S\", \"7S\", \"8S\", \"9S\", \"10S\", \"JS\", \"QS\", \"KS\")\n\nRecall that each card in a deck has one of four “suits” (Hearts, Diamonds, Clubs, and Spades) and one of four ranks (Ace, 2-10, Jack, Queen, King). In the above vector, each card is thus represented as a string (sequences of characters between quotation marks) with the (abbreviated) rank and (abbreviated) suit.\nOne hand of interest is called a “full house,” consisting of three cards of one rank and two cards of a different rank. (For example, {4 of Hearts, 3 of Diamonds, 4 of Spades, 4 of Clubs, 3 of Spades} would be a full house, but {4 of Hearts, 3 of Diamonds, 4 of Spades, 4 of Clubs, Queen of Spades} would not be a full house.)\nSo, we want to calculate the probability of getting a full house!\nSimulation and empirical calculation\nHere’s a sample (hehe, see what I did there?) piece of code to simulate the dealing of a single five-card hand.\n\nsample(deck_of_cards, 5)\n\n[1] \"4D\"  \"10H\" \"7S\"  \"2S\"  \"JH\" \n\n\nAs in the previous coin-flipping example, we will use a for-loop to simulate \\(5,000\\) different five-card hands. (Imagine that, after dealing each hand, we re-incorporate the dealt hand into the deck and shuffle thoroughly before the next hand is dealt.) We keep track of whether each hand was a full house in other \\(5,000\\)-element vector of Booleans; below are helper functions I defined in order to check whether a particular hand was a full house.\n\nsplit_card &lt;- function(card){\n  return(c(substr(card, 1, nchar(card) - 1), substr(card, nchar(card), nchar(card))))\n}\n\nis_full_house &lt;- function(hand){\n  ranks &lt;- numeric(5)\n  for(c in 1:5){\n    ranks[c] &lt;- split_card(hand[c])[1]\n  }\n  return(length(unique(ranks)) == 2)\n}\n\nWe then have the following code for the simulation.\n\nn_reps &lt;- 5000\nwas_house_full &lt;- numeric(n_reps)\nfor(m in 1:n_reps){\n  new_hand &lt;- sample(deck_of_cards, 5)\n  was_house_full[m] &lt;- is_full_house(new_hand)\n}\n\nAs before, we calculate the empirical probability using both the mean() function and the sum() function.\n\nfivecard_prob &lt;- mean(was_house_full)\nfivecard_prob\n\n[1] 0.0022\n\nsum(was_house_full) / n_reps\n\n[1] 0.0022\n\n\nThe true probability is approximately \\(0.0014\\) – the long-run average simulations strike again!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-1.html#we-can-count-on-you-you-do-it.",
    "href": "labs/lab-1.html#we-can-count-on-you-you-do-it.",
    "title": "Lab 1",
    "section": "We can count on you! (You do it.)",
    "text": "We can count on you! (You do it.)\nWell, that was fun! Shame that it’s over…\nWait a second. gasp We have two more exercises just for you to try – hurray!\nINSTRUCTIONS: For each of the following two exercises, your mission (should you choose to accept it) is to perform simulations from which you calculate the empirical probabilities of the specified events.\nAnd no, the order in which you accomplish these tasks does not matter. :) Happy counting!\nThe Birthday Problem\nWe have the following vector of strings, formatted MMMDD, wherein each entry is one of \\(365\\) days in a non-leap year.\n\nbdays &lt;- c(\"Jan01\", \"Jan02\", \"Jan03\", \"Jan04\", \"Jan05\", \"Jan06\", \"Jan07\", \"Jan08\", \"Jan09\", \"Jan10\", \"Jan11\", \"Jan12\", \"Jan13\", \"Jan14\", \"Jan15\", \"Jan16\", \"Jan17\", \"Jan18\", \"Jan19\", \"Jan20\", \"Jan21\", \"Jan22\", \"Jan23\", \"Jan24\", \"Jan25\", \"Jan26\", \"Jan27\", \"Jan28\", \"Jan29\", \"Jan30\", \"Jan31\", \"Feb01\", \"Feb02\", \"Feb03\", \"Feb04\", \"Feb05\", \"Feb06\", \"Feb07\", \"Feb08\", \"Feb09\", \"Feb10\", \"Feb11\", \"Feb12\", \"Feb13\", \"Feb14\", \"Feb15\", \"Feb16\", \"Feb17\", \"Feb18\", \"Feb19\", \"Feb20\", \"Feb21\", \"Feb22\", \"Feb23\", \"Feb24\", \"Feb25\", \"Feb26\", \"Feb27\", \"Feb28\", \"Mar01\", \"Mar02\", \"Mar03\", \"Mar04\", \"Mar05\", \"Mar06\", \"Mar07\", \"Mar08\", \"Mar09\", \"Mar10\", \"Mar11\", \"Mar12\", \"Mar13\", \"Mar14\", \"Mar15\", \"Mar16\", \"Mar17\", \"Mar18\", \"Mar19\", \"Mar20\", \"Mar21\", \"Mar22\", \"Mar23\", \"Mar24\", \"Mar25\", \"Mar26\", \"Mar27\", \"Mar28\", \"Mar29\", \"Mar30\", \"Mar31\", \"Apr01\", \"Apr02\", \"Apr03\", \"Apr04\", \"Apr05\", \"Apr06\", \"Apr07\", \"Apr08\", \"Apr09\", \"Apr10\", \"Apr11\", \"Apr12\", \"Apr13\", \"Apr14\", \"Apr15\", \"Apr16\", \"Apr17\", \"Apr18\", \"Apr19\", \"Apr20\", \"Apr21\", \"Apr22\", \"Apr23\", \"Apr24\", \"Apr25\", \"Apr26\", \"Apr27\", \"Apr28\", \"Apr29\", \"Apr30\", \"May01\", \"May02\", \"May03\", \"May04\", \"May05\", \"May06\", \"May07\", \"May08\", \"May09\", \"May10\", \"May11\", \"May12\", \"May13\", \"May14\", \"May15\", \"May16\", \"May17\", \"May18\", \"May19\", \"May20\", \"May21\", \"May22\", \"May23\", \"May24\", \"May25\", \"May26\", \"May27\", \"May28\", \"May29\", \"May30\", \"May31\", \"Jun01\", \"Jun02\", \"Jun03\", \"Jun04\", \"Jun05\", \"Jun06\", \"Jun07\", \"Jun08\", \"Jun09\", \"Jun10\", \"Jun11\", \"Jun12\", \"Jun13\", \"Jun14\", \"Jun15\", \"Jun16\", \"Jun17\", \"Jun18\", \"Jun19\", \"Jun20\", \"Jun21\", \"Jun22\", \"Jun23\", \"Jun24\", \"Jun25\", \"Jun26\", \"Jun27\", \"Jun28\", \"Jun29\", \"Jun30\", \"Jul01\", \"Jul02\", \"Jul03\", \"Jul04\", \"Jul05\", \"Jul06\", \"Jul07\", \"Jul08\", \"Jul09\", \"Jul10\", \"Jul11\", \"Jul12\", \"Jul13\", \"Jul14\", \"Jul15\", \"Jul16\", \"Jul17\", \"Jul18\", \"Jul19\", \"Jul20\", \"Jul21\", \"Jul22\", \"Jul23\", \"Jul24\", \"Jul25\", \"Jul26\", \"Jul27\", \"Jul28\", \"Jul29\", \"Jul30\", \"Jul31\", \"Aug01\", \"Aug02\", \"Aug03\", \"Aug04\", \"Aug05\", \"Aug06\", \"Aug07\", \"Aug08\", \"Aug09\", \"Aug10\", \"Aug11\", \"Aug12\", \"Aug13\", \"Aug14\", \"Aug15\", \"Aug16\", \"Aug17\", \"Aug18\", \"Aug19\", \"Aug20\", \"Aug21\", \"Aug22\", \"Aug23\", \"Aug24\", \"Aug25\", \"Aug26\", \"Aug27\", \"Aug28\", \"Aug29\", \"Aug30\", \"Aug31\", \"Sep01\", \"Sep02\", \"Sep03\", \"Sep04\", \"Sep05\", \"Sep06\", \"Sep07\", \"Sep08\", \"Sep09\", \"Sep10\", \"Sep11\", \"Sep12\", \"Sep13\", \"Sep14\", \"Sep15\", \"Sep16\", \"Sep17\", \"Sep18\", \"Sep19\", \"Sep20\", \"Sep21\", \"Sep22\", \"Sep23\", \"Sep24\", \"Sep25\", \"Sep26\", \"Sep27\", \"Sep28\", \"Sep29\", \"Sep30\", \"Oct01\", \"Oct02\", \"Oct03\", \"Oct04\", \"Oct05\", \"Oct06\", \"Oct07\", \"Oct08\", \"Oct09\", \"Oct10\", \"Oct11\", \"Oct12\", \"Oct13\", \"Oct14\", \"Oct15\", \"Oct16\", \"Oct17\", \"Oct18\", \"Oct19\", \"Oct20\", \"Oct21\", \"Oct22\", \"Oct23\", \"Oct24\", \"Oct25\", \"Oct26\", \"Oct27\", \"Oct28\", \"Oct29\", \"Oct30\", \"Oct31\", \"Nov01\", \"Nov02\", \"Nov03\", \"Nov04\", \"Nov05\", \"Nov06\", \"Nov07\", \"Nov08\", \"Nov09\", \"Nov10\", \"Nov11\", \"Nov12\", \"Nov13\", \"Nov14\", \"Nov15\", \"Nov16\", \"Nov17\", \"Nov18\", \"Nov19\", \"Nov20\", \"Nov21\", \"Nov22\", \"Nov23\", \"Nov24\", \"Nov25\", \"Nov26\", \"Nov27\", \"Nov28\", \"Nov29\", \"Nov30\", \"Dec01\", \"Dec02\", \"Dec03\", \"Dec04\", \"Dec05\", \"Dec06\", \"Dec07\", \"Dec08\", \"Dec09\", \"Dec10\", \"Dec11\", \"Dec12\", \"Dec13\", \"Dec14\", \"Dec15\", \"Dec16\", \"Dec17\", \"Dec18\", \"Dec19\", \"Dec20\", \"Dec21\", \"Dec22\", \"Dec23\", \"Dec24\", \"Dec25\", \"Dec26\", \"Dec27\", \"Dec28\", \"Dec29\", \"Dec30\", \"Dec31\")\n\nWe now address the Birthday Problem: Given a group of \\(n\\) people, what is the probability that at least \\(2\\) share a birthday? Consider \\(n = 10\\), \\(n = 100\\), and \\(n = 1,000\\).\nHelpful suggestions\nThis is yet another counting problem! For a given \\(n\\), what does your sample space look like?\nAny of the following functions may be useful in the simulation portion of this particular exercise: unique(), duplicated(), anyDuplicated(). To find out more, type ?&lt;function&gt; in the console and the documentation will appear in the Help tab on the right-hand side of the window.\nTwo-Card Poker Hand\nSuppose you are dealt a two-card hand; what is the probability that both cards are the same suit (i.e., Hearts, Diamonds, Clubs, Spades)? (You may use the deck_of_cards vector defined above to simulate this counting exercise.)",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab-5.html",
    "href": "labs/lab-5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Let \\(X\\) be a random variable, and let \\(g\\) be some function. Because \\(X\\) is random, the new variable \\(Y=g(X)\\) is also random. Given what we know about \\(X\\), what is the distribution of \\(Y\\)? This simple question will preoccupy us for the next seventy-five minutes.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#problem--1-recall-lecture",
    "href": "labs/lab-5.html#problem--1-recall-lecture",
    "title": "Lab 5",
    "section": "Problem -1: recall lecture",
    "text": "Problem -1: recall lecture\nIf \\(\\Theta\\sim\\text{Unif}(-\\pi/2,\\,\\pi/2)\\), then what is the distribution of \\(X=\\tan\\Theta\\)? We know that \\(\\text{Range}(X)=\\mathbb{R}\\), so for any \\(x\\in\\mathbb{R}\\), we have\n\\[\n\\begin{aligned}\nF_X(x)\n&=\nP(X\\leq x)\n\\\\\n&=\nP(\\tan\\Theta\\leq x)\n\\\\\n&=\nP(\\Theta\\leq \\tan^{-1}x)\n\\\\\n&=\nF_{\\Theta}(\\tan^{-1}x)\n\\\\\n&=\n\\frac{\\tan^{-1}x}{\\pi}+\\frac{1}{2}.\n\\end{aligned}\n\\]\nSo the density of \\(X\\) is\n\\[\nf_X(x)=\\frac{\\text{d}}{\\text{d}x}F_X(x)=\\frac{\\text{d}}{\\text{d}x}\\left[\\frac{\\tan^{-1}x}{\\pi}+\\frac{1}{2}\\right]=\\frac{1}{\\pi(1+x^2)},\\quad x\\in\\mathbb{R}.\n\\]\nThis is the density of the Cauchy distribution.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#problem-0-watch-gwen",
    "href": "labs/lab-5.html#problem-0-watch-gwen",
    "title": "Lab 5",
    "section": "Problem 0: watch Gwen!",
    "text": "Problem 0: watch Gwen!\nIf \\(Z\\sim\\text{N}(0,\\, 1)\\), then what is the pdf of \\(Y=Z^2\\)? Turns out it’s a member of the gamma family.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#problem-1-now-you-try",
    "href": "labs/lab-5.html#problem-1-now-you-try",
    "title": "Lab 5",
    "section": "Problem 1: now you try",
    "text": "Problem 1: now you try\nConsider \\(X\\sim \\text{Gamma}(1,\\,1)\\). Its density is\n\\[\nf_X(x)=e^{-x},\\quad x&gt;0.\n\\]\n\nWhat is the cdf of \\(X\\)?\nWhat are the range and pdf of \\(Y=\\ln X\\)?\nSimulate n=5000 draws of \\(Y\\). Plot a histogram, and add a line plot of the density you derived in part b. They should match!",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#interlude",
    "href": "labs/lab-5.html#interlude",
    "title": "Lab 5",
    "section": "Interlude",
    "text": "Interlude\nGiven \\(X\\sim f_X\\), we want the density of \\(Y=g(X)\\). In the three examples, you followed the same basic steps:\n\nwrite the generic cdf of \\(Y\\): \\(F_Y(y)=P(Y\\leq y)=P(g(X)\\leq y)\\);\nrewrite the event inside until \\(X\\) is by itself (you probably have to undo or invert \\(g\\) to do this);\nsince \\(X\\) is by itself, rewrite the probability using the cdf of \\(X\\);\ndifferentiate (you probably have to use the chain rule to do this).\n\nThe basic template can be neatly summarized with the so-called change-of-variables formula, which tells you how to compute the density of \\(Y\\) using the density of \\(X\\) and the transformation \\(g\\):\n\\[\nf_Y(y)=f_X\\left(g^{-1}(y)\\right)\n    \\left|\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)\\right|,\\quad y\\in\\text{Range}(Y).\n\\]\n\n\n\n\n\n\nWanna see the proof?\n\n\n\n\n\nAssume…\n\n\\(X\\) is absolutely continuous with pdf \\(f_X\\);\n\\(g\\) is defined for all \\(x\\in\\text{Range}(X)\\);\n\\(g\\) is differentiable and either strictly increasing or strictly decreasing (hence, invertible).\n\nThere are two cases:\n\n\nStrictly increasing\nIf \\(g\\) is strictly increasing, then \\(g^{-1}\\) is strictly increasing also. This means that \\(\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)\\) must be positive for all \\(y\\)! It also means that \\(g^{-1}\\) is order-preserving. If \\(a\\leq b\\), then \\(g^{-1}(a)\\leq g^{-1}(b)\\).\nFix arbitrary \\(y\\in\\text{Range}(Y)\\). Then:\n\\[\n\\begin{aligned}\n    F_Y(y)\n    &=\n    P(Y\\leq y)\n    \\\\\n    &=\n    P\\left(g(X)\\leq y\\right)\n    \\\\\n    &=\n    P\\left(X\\leq g^{-1}(y)\\right)\n    \\\\\n    &=\n    F_X\\left(g^{-1}(y)\\right)\n    .\n\\end{aligned}\n\\]\nTaking a derivative and applying the chain rule gives\n\\[\n\\begin{aligned}\n    f_Y(y)\n    &=\n    \\frac{\\text{d}}{\\text{d} y}F_X\\left(g^{-1}(y)\\right)\n    \\\\\n    &=\n    f_X\\left(g^{-1}(y)\\right)\\underbrace{\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)}_{\\text{positive!}}\n    \\\\\n    &=\n    f_X\\left(g^{-1}(y)\\right)\n    \\left|\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)\\right|.\n\\end{aligned}\n\\]\n\nStrictly decreasing\nIf \\(g\\) is strictly decreasing, then \\(g^{-1}\\) is strictly decreasing also. This means that \\(\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)\\) must be negative for all \\(y\\)! It also means that \\(g^{-1}\\) is order-reversing. If \\(a\\leq b\\), then \\(g^{-1}(a)\\geq g^{-1}(b)\\).\nFix arbitrary \\(y\\in\\text{Range}(Y)\\). Then:\n\\[\n\\begin{aligned}\n    F_Y(y)\n    &=\n    P(Y\\leq y)\n    \\\\\n    &=\n    P\\left(g(X)\\leq y\\right)\n    \\\\\n    &=\n    P\\left(X&gt; g^{-1}(y)\\right)\n    \\\\\n    &=\n    1-P\\left(X\\leq g^{-1}(y)\\right)\n    \\\\\n    &=\n    1-F_X\\left(g^{-1}(y)\\right)\n    .\n\\end{aligned}\n\\] Taking a derivative and applying the chain rule gives\n\\[\n\\begin{align*}\n    f_Y(y)\n    &=\n    \\frac{\\text{d}}{\\text{d} y}[1-F_X\\left(g^{-1}(y)\\right)]\n    \\\\\n    &=\n    {\\color{red}-}f_X\\left(g^{-1}(y)\\right)\\underbrace{\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)}_{\\text{negative!}}\n    \\\\\n    &=\n    f_X\\left(g^{-1}(y)\\right)\n    \\left|\\frac{\\text{d}}{\\text{d} y}g^{-1}(y)\\right|.\n\\end{align*}\n\\]\n\n\nEither way, we got to the same place.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#problem-1.5",
    "href": "labs/lab-5.html#problem-1.5",
    "title": "Lab 5",
    "section": "Problem 1.5",
    "text": "Problem 1.5\nUse the change-of-variables formula to re-do Problem 1. You should get the same answer.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-5.html#problem-2-location-scale-transformations",
    "href": "labs/lab-5.html#problem-2-location-scale-transformations",
    "title": "Lab 5",
    "section": "Problem 2: location-scale transformations",
    "text": "Problem 2: location-scale transformations\nLet \\(X\\) be an absolutely continuous random variable with pdf \\(f_X\\), let \\(a&gt;0\\) and \\(b\\in\\mathbb{R}\\) be constants, and consider the new random variable \\(Y=aX+b\\).\n\nWhat is \\(E(Y)\\)?\nWhat is \\(\\text{var}(Y)\\)?\nUse the change-of-variables formula to find the density of \\(Y\\)?\nIn the special case where \\(X\\sim\\text{N}(0,\\,1)\\), what are \\(E(Y)\\), \\(\\text{var}(Y)\\), and the density of \\(Y\\)? There’s no need to re-derive anything here. Just plug what you know about N(0, 1) into the formulas from parts a, b, and c.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab-6.html",
    "href": "labs/lab-6.html",
    "title": "Lab 6 - simulation",
    "section": "",
    "text": "The quantile function of a random variable is the (generalized) inverse of its cdf. So \\(F^{-1}\\). It is the function that, given a probability \\(\\alpha\\in(0,\\,1)\\), returns the cut-off point on the number line that has that much probability to the left. So the \\(\\alpha\\)th quantile \\(q_{\\alpha}\\) satisfies \\(P(X\\leq q_\\alpha) = \\alpha\\) and \\(F^{-1}(\\alpha)=q_\\alpha\\). Here is the picture:\n\n\n\n\nThe median is the \\(\\alpha=0.5\\) quantile. The quantiles of the standard normal distribution are famous:\n\nqnorm(0.95)\n\n[1] 1.644854\n\nqnorm(0.975)\n\n[1] 1.959964\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nEvery distribution family has a q- function that, given \\(p\\in(0,\\,1)\\), returns the quantile \\(F^{-1}(p)=q_p\\):\n\n# discrete \n\nqbinom(p, size, prob) # Bernoulli is just binomial with size = 1\nqgeom(p, prob)\nqpois(p, lambda)\n\n# continuous\n\nqnorm(p, mean = 0, sd = 1)\nqgamma(p, shape, rate = 1)\nqunif(p, min = 0, max = 1)\nqcauchy(p)\n\n\n\n\n\n\n\nWhat about the discrete case?\n\n\n\n\n\nIn the discrete case, the CDF is a piecewise constant step function. Definitely not invertible. And in general, the cdf \\(F\\) is not invertible, like in this picture:\n\n\n\n\nSo what do we mean by \\(F^{-1}\\) then? That’s when we invoke the generalized inverse and define\n\\[\nF^{-1}(\\alpha)=\\inf\\{x\\in\\mathbb{R}:\\alpha\\leq F(x)\\}.\n\\]\n“inf” stands for infimum, which in mathematics is a special generalization of the minimum. You don’t have to know about any of this, by the way.\n\n\n\n\nLet \\(X\\sim \\text{Cauchy}\\), meaning its cdf is\n\\[\nF_X(x)=\\frac{\\tan^{-1}x}{\\pi}+\\frac{1}{2},\\quad x\\in\\mathbb{R}.\n\\]\n\nFind the inverse cdf \\(F_X^{-1}(y)\\), \\(y\\in(0,\\,1)\\);\nUse your inverse cdf formula to compute the 60% quantile of \\(X\\);\nUse the qcauchy function to compute the same quantile, and verify that you get the same number.\n\nLet \\(X\\sim\\text{Gamma}(1,\\,\\beta)\\). So the pdf of \\(X\\) is\n\\[\nf_X(x)=\\beta e^{-\\beta x},\\quad x&gt;0.\n\\]\n\nFind the cdf \\(F_X(x)=P(X\\leq x)\\);\nFind the inverse cdf \\(F_X^{-1}(y)\\), \\(y\\in(0,\\,1)\\);\nUse your inverse cdf formula to compute the median of \\(X\\). It will be a function of \\(\\beta\\);\nFix \\(\\beta = 2\\). Use the qgamma function to compute the median of \\(X\\), and verify that you get the same number as you get when you use your formula from part c.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-1",
    "href": "labs/lab-6.html#problem-1",
    "title": "Lab 6 - simulation",
    "section": "",
    "text": "Let \\(X\\sim \\text{Cauchy}\\), meaning its cdf is\n\\[\nF_X(x)=\\frac{\\tan^{-1}x}{\\pi}+\\frac{1}{2},\\quad x\\in\\mathbb{R}.\n\\]\n\nFind the inverse cdf \\(F_X^{-1}(y)\\), \\(y\\in(0,\\,1)\\);\nUse your inverse cdf formula to compute the 60% quantile of \\(X\\);\nUse the qcauchy function to compute the same quantile, and verify that you get the same number.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-2",
    "href": "labs/lab-6.html#problem-2",
    "title": "Lab 6 - simulation",
    "section": "",
    "text": "Let \\(X\\sim\\text{Gamma}(1,\\,\\beta)\\). So the pdf of \\(X\\) is\n\\[\nf_X(x)=\\beta e^{-\\beta x},\\quad x&gt;0.\n\\]\n\nFind the cdf \\(F_X(x)=P(X\\leq x)\\);\nFind the inverse cdf \\(F_X^{-1}(y)\\), \\(y\\in(0,\\,1)\\);\nUse your inverse cdf formula to compute the median of \\(X\\). It will be a function of \\(\\beta\\);\nFix \\(\\beta = 2\\). Use the qgamma function to compute the median of \\(X\\), and verify that you get the same number as you get when you use your formula from part c.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-3",
    "href": "labs/lab-6.html#problem-3",
    "title": "Lab 6 - simulation",
    "section": "Problem 3",
    "text": "Problem 3\nIf you took AP Statistics or STA 101, you probably learned about Student’s \\(t\\) distribution. This is a family of continuous distributions with heavier tails than the normal, and the density is:\n\\[\nf_X(x;\\,\\nu)=\\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\pi\\nu}}\\left(1+\\frac{1}{\\nu}x^2\\right)^{-\\frac{\\nu+1}{2}},\\quad x\\in\\mathbb{R}.\n\\]\nThis family has one parameter \\(\\nu&gt;0\\) called the degrees of freedom. Okay, that’s a big rotten mess, but whatever. If we wanted to simulate it, all we have to do is simulate from \\(\\text{Unif}(0,\\, 1)\\), and then plug those numbers into the inverse cdf of the \\(t\\) distribution. The transformed numbers are guaranteed to follow the \\(t\\) distribution. Let’s see that!\nStudent’s \\(t\\) has it’s own d- and q- functions:\n\ndt(x, df)\nqt(p, df)\n\ndt evaluates the pdf, and qt evaluates the inverse cdf (ie the quantile function). Implement the following:\n\nSimulate \\(n=5000\\) numbers from \\(\\text{Unif}(0,\\, 1)\\);\nPlug them into the inverse cdf of the \\(t\\) distribution with df = 10;\nPlot a histogram of these transformed numbers;\nAdd on top of the histogram a line plot of the density of the \\(t\\) distribution with ten degrees of freedom;\nThey had better match!",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-4",
    "href": "labs/lab-6.html#problem-4",
    "title": "Lab 6 - simulation",
    "section": "Problem 4",
    "text": "Problem 4\nLet \\(X\\sim\\text{Gamma}(1,\\,\\beta)\\). So the pdf of \\(X\\) is\n\\[\nf_X(x)=\\beta e^{-\\beta x},\\quad x&gt;0.\n\\]\n\nUse your inverse CDF formula from Part 1 to implement inverse transform sampling and simulate \\(\\text{Gamma}(1,\\,\\beta)\\) for \\(\\beta = 2\\).\nPlot a histogram of 5000 draws from your sampler, and add a line plot of the \\(\\text{Gamma}(1,\\,2)\\) density on top. They had better match!",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-5",
    "href": "labs/lab-6.html#problem-5",
    "title": "Lab 6 - simulation",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(X\\sim \\text{Cauchy}\\). Use your inverse CDF formula from Part 1 to implement inverse transform sampling for the Cauchy distribution. Plot a histogram of 5000 draws from your sampler, and add a line plot of the Cauchy density on top. They had better match!\n\n\n\n\n\n\nNote\n\n\n\nYou may find that you have to fiddle with the plot a little bit to get a picture that it easy to read. Do you know why that is?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab-6.html#problem-6",
    "href": "labs/lab-6.html#problem-6",
    "title": "Lab 6 - simulation",
    "section": "Problem 6",
    "text": "Problem 6\nThe bottom line of all of this is the universality of the uniform. The fundamental principle of simulation is that any distribution can be simulated by first simulating from the standard uniform, and then applying a transformation.\nThe Box-Muller method says that we can simulate the standard normal in the following way:\n\\[\n\\begin{align*}\nU_1,\\,U_2&\\overset{\\textrm{iid}}{\\sim}\\textrm{Unif}(0,\\,1)\\\\\nZ&=\\sqrt{-2\\ln U_1}\\cos(2\\pi U_2)\n\\end{align*}\n\\]\nSo \\(Z\\sim\\text{N}(0,\\,1)\\). It is not hard to prove this if you’ve taken multivariable calculus (yaaay polar coordinates), but our course does not assume this. Nevertheless, we can still implement the sampler and check that it works.\n\nUse the Box-Muller method to simulate 5000 random numbers from N(0, 1). Check that you did it right by plotting the histogram and superimposing the standard normal density;\nModify your code to simulate \\(\\text{N}(\\mu=-3.5,\\,\\sigma^2=0.58)\\), and compare a histogram with a density to verify that it works.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "psets/pset_4.html",
    "href": "psets/pset_4.html",
    "title": "Problem Set 4",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-0",
    "href": "psets/pset_4.html#problem-0",
    "title": "Problem Set 4",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-1",
    "href": "psets/pset_4.html#problem-1",
    "title": "Problem Set 4",
    "section": "Problem 1",
    "text": "Problem 1\nFinish Lab 4! To remind you, we were modeling insurance claims in the following way:\n\n\\(N\\sim\\text{Poisson}(\\lambda=100)\\) is a discrete random variable counting the number of claims that an insurance company receives in a given month;\n\\(X_1\\), \\(X_2\\), … are continuous random variables representing the dollar amount of each claim;\n\\(S=X_1+X_2+...+X_N\\) is the total amount of money the company has to pay out. It’s a new random variable that inherits its randomness from both \\(N\\) and the \\(X_i\\). If \\(S\\) ends up being too large, the company will go broke.\n\nFor simplicity we assume everything is independent here, which is a totally bogus assumption. But oh well:\n\nZoom in for a second on a single claim amount \\(X\\) and assume \\(X\\sim\\text{Gamma}(\\alpha,\\,\\beta)\\). If we know from historical experience that claims are typically around $10,000 with a standard deviation of $2,000, what values should we pick for \\(\\alpha\\) and \\(\\beta\\) so that \\(X\\) has the right center and spread?\nUse R to simulate n = 5000 random numbers from the gamma distribution. Plot a histogram of these numbers, and overlay a line plot of the density.\nVerify that the sample mean and sample variance of your random numbers are close to the prescriptions from part a. If they are not, revisit part a and adjust your choice of \\(\\alpha\\) and \\(\\beta\\) until this works.\nWhat is the probability \\(P(X &gt; 15000)\\)? Calculate this probability exactly using the appropriate p- function, and also approximate it using your random numbers from part b. Verify that the two numbers are close.\nWrite a function in R that simulates \\(S\\). So your function should spit out a single number, generated in the following way:\n\nSimulate \\(N\\);\nGiven the result of Step 1, simulate independent \\(X_1\\), \\(X_2\\), …, \\(X_N\\);\nGiven the result of Step 2, return \\(S=X_1+X_2+...+X_N\\).\n\nUsing the function you wrote in the previous task, simulate \\(n=5000\\) possible values for the random variable \\(S\\) and plot a histogram of them.\nUse your simulations to approximate the probability \\(P(S&gt;130000)\\).\nCompute the sample mean and the sample variance of your simulations. Based on these, can you conjecture how the parameters of the underlying \\(\\text{Poisson}(\\lambda)\\) and \\(\\text{Gamma}(\\alpha,\\,\\beta)\\) distributions are related to \\(E(S)\\) and \\(\\text{var}(S)\\)? That is, propose formulas \\(E(S)=h(\\lambda,\\,\\alpha,\\,\\beta)\\) and \\(\\text{var}(S)=g(\\lambda,\\,\\alpha,\\,\\beta)\\) that describe how the underlying Poisson and gamma parameters determine the moments of \\(S\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-2",
    "href": "psets/pset_4.html#problem-2",
    "title": "Problem Set 4",
    "section": "Problem 2",
    "text": "Problem 2\nIf \\(X\\sim\\text{Binomial}(n,\\,p)\\), show that\n\\[\nE\\left[\\frac{1}{X+1}\\right]=\\frac{1-(1-p)^{n+1}}{(n+1)p}.\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-3",
    "href": "psets/pset_4.html#problem-3",
    "title": "Problem Set 4",
    "section": "Problem 3",
    "text": "Problem 3\nAn absolutely continuous random variable \\(X\\) has pdf\n\\[\nf(x)=\\begin{cases}\n\\frac{3}{22}[5 - (x-1)^2] & 1\\leq x \\leq3\\\\\n0 & \\text{else}.\n\\end{cases}\n\\]\n\nWhat is the range of \\(X\\)?\nConfirm that \\(f\\) is a valid pdf.\nDerive the formula for the cdf of \\(X\\) and plot it.\nCompute \\(P(0.9 &lt; X &lt; 1.1)\\).\nCompute \\(E(X)\\).\nCompute \\(\\text{var}(X)\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-4",
    "href": "psets/pset_4.html#problem-4",
    "title": "Problem Set 4",
    "section": "Problem 4",
    "text": "Problem 4\nA point is chosen at random on a line segment of length \\(L\\). Interpret this statement, and find the probability that the ratio of the shorter to the longer segment is less than \\(\\frac{1}{4}\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-5",
    "href": "psets/pset_4.html#problem-5",
    "title": "Problem Set 4",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(X\\) be any absolutely continuous random variable with pdf \\(f\\) and cdf \\(F\\), and assume that \\(E[(X-a)^2]\\) and \\(E\\left[|X-a|\\right]\\) are finite for all \\(a\\in \\mathbb{R}\\).\n\nCompute and interpret\n\n\\[\na_0=\\underset{a\\in\\mathbb{R}}{\\arg\\min}\\,E[(X-a)^2].\n\\]\n\nCompute and interpret\n\n\\[\nb_0=\\underset{b\\in\\mathbb{R}}{\\arg\\min}\\,E\\left[|X-b|\\right].\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_4.html#problem-6",
    "href": "psets/pset_4.html#problem-6",
    "title": "Problem Set 4",
    "section": "Problem 6",
    "text": "Problem 6\nConsider \\(X\\sim\\textrm{Gamma}(\\alpha,\\,\\beta)\\).\n\nFind \\(M_X(t)=E[e^{tX}]\\), the moment generating function of \\(X\\). For what values of \\(t\\) is it defined?\nUse the moment-generating function to compute \\(E(X)\\).\nUse the moment-generating function to compute \\(\\text{var}(X)\\).\nIf \\(c&gt;0\\), what is the distribution of \\(Y=cX\\)?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 4"
    ]
  },
  {
    "objectID": "psets/pset_3.html",
    "href": "psets/pset_3.html",
    "title": "Problem Set 3",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#problem-0",
    "href": "psets/pset_3.html#problem-0",
    "title": "Problem Set 3",
    "section": "",
    "text": "Recommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#problem-1",
    "href": "psets/pset_3.html#problem-1",
    "title": "Problem Set 3",
    "section": "Problem 1",
    "text": "Problem 1\nSay you have an unfamiliar coin on hand which may or may not be fair. So this coin lands on heads with some unknown probability \\(p\\), which is not necessarily equal to 1/2. Nevertheless, you want to somehow use this coin to generate the outcome of the flip of a fair coin. Consider the following algorithm for doing this:\n\nFlip the coin;\nFlip the coin again;\nIf both flips land on heads or if both flips land on tails, start over from Step (i);\nIf the two flips are different, let the result of the last flip be the result of the experiment.\n\nThen:\n\nShow that if you generate flips using this algorithm, the result is equally likely to be either heads or tails.\nHere is another possible algorithm: flip the coin until the last two flips are different, and let the result be the outcome of the final flip. Are heads and tails equally likely using this procedure?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#problem-2",
    "href": "psets/pset_3.html#problem-2",
    "title": "Problem Set 3",
    "section": "Problem 2",
    "text": "Problem 2\nTwo balls are chosen randomly from an urn containing 8 green, 4 black, and 2 orange balls. Suppose that we win $2 for each black ball selected, we lose $1 for each green ball selected, and we earn nothing for each orange ball selected. Let \\(X\\) denote our winnings.\n\nMake a table with the possible values of \\(X\\) and the probabilities of each value.\nSketch the pmf of \\(X\\).\nSketch the cdf of \\(X\\).\nCompute the expected value of \\(X\\).",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#problem-3",
    "href": "psets/pset_3.html#problem-3",
    "title": "Problem Set 3",
    "section": "Problem 3",
    "text": "Problem 3\nLet \\(X\\) be a random variable with the following pmf:\n\n\n\n\\(x\\)\n\\(P(X=x)\\)\n\n\n\n\n-1\n0.500\n\n\n0\n0.250\n\n\n1\n0.125\n\n\n2\n0.125\n\n\n\n\nWhat is the mean of \\(X\\)?\nWhat is the pmf of \\(Y = 2X-3\\)?\nWhat is the mean of \\(Y\\)?\nWhat is the pmf of \\(W = X^2\\)?\nWhat is the mean of \\(W\\)?\nWhat is the conditional pmf of \\(X\\) given \\(X \\neq 0\\)?\nWhat is the conditional mean of \\(X\\) given \\(X \\neq 0\\)?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#problem-4",
    "href": "psets/pset_3.html#problem-4",
    "title": "Problem Set 3",
    "section": "Problem 4",
    "text": "Problem 4\nForty-nine members of the Cleveland Orchestra string section wish to compare their birthdays. Assume that no one has February 29th and that all birthdays are independent.\n\nWhat is the expected number of pairs of people with the same birthday?\nWhat is the expected number of days on which at least two players were born?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_3.html#submission",
    "href": "psets/pset_3.html#submission",
    "title": "Problem Set 3",
    "section": "Submission",
    "text": "Submission\nYou are free to compose your solutions for this problem set however you wish (scan or photograph written work, handwriting capture on a tablet device, LaTeX, Quarto, whatever) as long as the final product is a single PDF file. You must upload this to Gradescope and mark the pages associated with each problem.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 3"
    ]
  },
  {
    "objectID": "psets/pset_0.html",
    "href": "psets/pset_0.html",
    "title": "Problem Set 0",
    "section": "",
    "text": "Nature laughs at the difficulties of integration.\nThis is ostensibly calculus review, but each problem is a piece of probability in disguise. We will illuminate these connections throughout the semester, and I will refer to Problem Set 0 often. Stay tuned!",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-0",
    "href": "psets/pset_0.html#problem-0",
    "title": "Problem Set 0",
    "section": "Problem 0",
    "text": "Problem 0\nRecommend some music for us to listen to while we grade this.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-1",
    "href": "psets/pset_0.html#problem-1",
    "title": "Problem Set 0",
    "section": "Problem 1",
    "text": "Problem 1\nExplain why this is horrific notation:\n\\[\n    \\int_0^x f(x)\\,\\textrm{d} x.\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-2",
    "href": "psets/pset_0.html#problem-2",
    "title": "Problem Set 0",
    "section": "Problem 2",
    "text": "Problem 2\nAssume \\(\\lambda&gt;0\\) is a constant and compute\n\\[\n    \\sum\\limits_{n=0}^\\infty n \\frac{\\lambda^n}{n!}e^{-\\lambda}\n    .\n\\]",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-3",
    "href": "psets/pset_0.html#problem-3",
    "title": "Problem Set 0",
    "section": "Problem 3",
    "text": "Problem 3\nHere is a very silly function:\n\\[\n    h(x)\n    =\n    \\exp\\left(-\\frac{1}{2}\\frac{(x-\\mu)^2}{\\sigma^2}\\right)\n    ,\\quad\n    -\\infty&lt;x&lt;\\infty\n    .\n\\]\nTreat \\(-\\infty&lt;\\mu&lt;\\infty\\) and \\(\\sigma&gt;0\\) as constants and compute the value(s) of \\(x\\) at which \\(h\\) has inflection points.\n\n\n\n\n\n\nHint\n\n\n\n\n\nHere is an example of what \\(h\\) might look like in the special case where \\(\\mu = 1\\) and \\(\\sigma=2\\):\n\n\n\n\n\n\n\n\nBefore you start doing any math, can you use the picture to guess what the answer will be?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-4",
    "href": "psets/pset_0.html#problem-4",
    "title": "Problem Set 0",
    "section": "Problem 4",
    "text": "Problem 4\nHere is another inordinately silly function:\n\\[\n\\Gamma(x)=\\int_0^\\infty y^{x-1}e^{-y}\\,\\textrm{d} y,\\quad x&gt;0.\n\\]\nProve that \\(\\Gamma(x+1)=x\\Gamma(x)\\).\n\n\n\n\n\n\nHint\n\n\n\n\n\nStart on the left-hand side by writing out \\(\\Gamma(x+1)\\) and evaluating the integral by parts.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-5",
    "href": "psets/pset_0.html#problem-5",
    "title": "Problem Set 0",
    "section": "Problem 5",
    "text": "Problem 5\nLet \\(f\\) be any function with the following properties:\n\n\n\\(f\\) is twice continuously differentiable in a neighborhood of 0;\n\n\\(f(0) = 0\\);\n\n\\(f'(0) = 0\\);\n\n\\(f''(0) = 1\\).\n\nAssume \\(t\\) is a constant and compute\n\\[\n    \\lim_{x\\to\\infty} xf\\left(\\frac{t}{\\sqrt{x}}\\right)\n    .\n\\]\n\n\n\n\n\n\nHint\n\n\n\n\n\nAre you allowed to simply “plug in” \\(\\infty\\) for \\(x\\) and simplify the expression? If so, why is that allowed? If not, what do you have to do instead?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#problem-6",
    "href": "psets/pset_0.html#problem-6",
    "title": "Problem Set 0",
    "section": "Problem 6",
    "text": "Problem 6\nConsider this integral:\n\\[\n    \\int_2^\\infty\n    \\frac{1}{x(\\ln x)^p}\\textrm{d} x\n    .\n\\]\n\nUse a computer to create a single plot with many lines, each graphing the integrand for a different value of \\(p\\). Consider \\(p\\) equal to -2, -1.5, -1, 0, 1, and 5, and make the \\(x\\)-axis of your plot run from 2 to 15.\nShow that \\(\\lim_{x\\to\\infty}\\frac{1}{x(\\ln x)^p}=0\\) for all values of \\(-\\infty&lt;p&lt;\\infty\\).\nFor what values of \\(p\\) does the integral converge? When it does converge, what is its value?\nConsult the picture you created in part (a), and write a few sentences explaining conceptually why the integral converges for some values of \\(p\\) but not others.\n\n\n\n\n\n\n\n“Use a computer”\n\n\n\nThis is deliberately vague. You are welcome to use any tool you are familiar with: graphing calculator, GeoGebra, Desmos, R, Matlab, Mathematica, WolframAlpha, Julia, Maple, etc. Just make sure to plop a single image file, however crude, into your final submission.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nWhen taking the limit or evaluating the integral, can you use the same technique for all values of \\(p\\), or do you need a different technique depending on what \\(p\\) is?",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#submission",
    "href": "psets/pset_0.html#submission",
    "title": "Problem Set 0",
    "section": "Submission",
    "text": "Submission\nYou are free to compose your solutions for this problem set however you wish (scan or photograph written work, handwriting capture on a tablet device, LaTeX, Quarto, whatever) as long as the final product is a single PDF file. You must upload this to Gradescope and mark the pages associated with each problem.",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "psets/pset_0.html#point-values",
    "href": "psets/pset_0.html#point-values",
    "title": "Problem Set 0",
    "section": "Point values",
    "text": "Point values\n\n\nProblem\nPoints\n\n\n\n1\n2\n\n\n2\n3\n\n\n3\n3\n\n\n4\n3\n\n\n5\n3\n\n\n6.a\n2\n\n\n6.b\n3\n\n\n6.c\n3\n\n\n6.d\n2\n\n\nTOTAL\n24",
    "crumbs": [
      "Problem Sets",
      "Problem Set 0"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 240 Probability for Inference, Modeling, and Data Analysis",
    "section": "",
    "text": "Below is a prospective outline for the course. Due dates are firm, but topics may change with advanced notice.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nPREPARE\nTOPIC\nMATERIALS\nDUE\n\n\n\n0\nWed, Jan 8\n\nDS: 1.1 - 1.2\nWelcome!\nslides\n\n\n\n\nThu, Jan 9\n\nLab 0: calculus review\nslides\n\n\n\n1\nMon, Jan 13\n\nDS: 1.3 - 1.4\nSet theory\nnotes\n\n\n\n\nWed, Jan 15\n\nDS: 1.5\nProbability rules\nnotes\n\n\n\n\nThu, Jan 16\n\nLab 1\n\n\nPSET 0 @ 12PM\n\n\n\nFri, Jan 17\n\n\n\n\nLab 1 @ 5:00 PM\n\n\n2\nMon, Jan 20\n\nMLK Day - No Lecture\n\n\n\n\n\nWed, Jan 22\n\nDS: 1.6 - 1.8\nCounting Snow Day - No Lecture\n\n\nvideos notes\n\n\n\n\n\nThu, Jan 23\n\nOH w/ Gwen\n\n\n\n\n\nFri, Jan 24\n\n\n\n\nPSET 1 @ 12PM\n\n\n3\nMon, Jan 27\n\nDS: 2\nConditional probability 1\n\nPlay around! Play around some more!\n\n\n\n\n\nWed, Jan 29\n\nDS: 2\nConditional probability 2\nnotes\n\n\n\n\nThu, Jan 30\n\nLab 2\n\n\nLab 2 @ 11:59 PM\n\n\n4\nMon, Feb 3\n\nDS: 3.1, 3.3, 4.1\nDiscrete random variables\nnotes\n\n\n\n\nWed, Feb 5\n\nDS: 5.1 - 5.4\nDiscrete random variables\nnotes\n\n\n\n\nThu, Feb 6\n\nLab 3\n\n\nPSET 2 @ 12PM Lab 3 @ 11:59 PM\n\n\n5\nMon, Feb 10\n\nDS: 4.1 - 4.3\nDiscrete random variables\nnotes\n\n\n\n\nWed, Feb 12\n\nDiscrete random variables\n\n\n\n\n\nThu, Feb 13\n\nExam Review\npractice\n\n\n\n\nFri, Feb 14\n\n\n\n\nPSET 3 @ 5PM\n\n\n6\nMon, Feb 17\n\nMidterm 1\n\n\n\n\n\nWed, Feb 19\n\nSnow Day - No Lecture\n\n\n\n\n\nThu, Feb 20\n\nSnow Day - No Lab\n\n\n\n\n7\nMon, Feb 24\n\nDS: 3.2 - 3.3\nContinuous random variables\n\n\n\n\n\nWed, Feb 26\n\nDS: 5.6 - 5.7\nContinuous random variables\n\n\n\n\n\nThu, Feb 27\n\nLab 4\n\n\nLab 4 @ 11:59 PM\n\n\n8\nMon, Mar 3\n\nDS: 4.1 - 4.5\nContinuous random variables\n\n\n\n\n\nWed, Mar 5\n\nDS: 3.8\nContinuous random variables\n\n\n\n\n\nThu, Mar 6\n\nDS: 12\nLab 5\n\n\nLab 5 @ 11:59 PM\n\n\n\nFri, Mar 7\n\n\n\n\nPSET 4 @ 5PM\n\n\n9\nMon, Mar 10\n\nSpring Break - No Lecture\n\n\n\n\n\nWed, Mar 12\n\nSpring Break - No Lecture\n\n\n\n\n\nThu, Mar 13\n\nSpring Break - No Lab\n\n\n\n\n10\nMon, Mar 17\n\nDS: 3.4 - 3.7\nJoint distributions\n\n\n\n\n\nWed, Mar 19\n\nDS: 3.4 - 3.7\nJoint distributions\n\n\n\n\n\nThu, Mar 20\n\nLab 6\n\n\nLab 6 @ 11:59 PM\n\n\n11\nMon, Mar 24\n\nDS: 3.4 - 3.7\nJoint distributions\n\n\n\n\n\nWed, Mar 26\n\nDS: 4.6\nCovariance\n\n\n\n\n\nThu, Mar 27\n\nExam Review\n\n\n\n\n\nSat, Mar 29\n\n\n\n\nPSET 5 @ 8AM\n\n\n12\nMon, Mar 31\nMore practice\nMidterm 2\n\n\n\n\n\nWed, Apr 2\n\nDS: 6\nSums and averages\n\n\n\n\n\nThu, Apr 3\n\nLab 7\n\n\nLab 7 @ 11:59 PM\n\n\n13\nMon, Apr 7\n\nDS: 6\nLimit theorems\n\n\n\n\n\nWed, Apr 9\n\nStatistics\n\n\n\n\n\nThu, Apr 10\n\nLab 8\n\n\nLab 8 @ 11:59 PM\n\n\n\nSat, Apr 12\n\nWhence AP Stats?  (optional make-up lecture)\n\n\n\n\n14\nMon, Apr 14\n\nMaximum likelihood\n\n\n\n\n\nWed, Apr 16\n\nMaximum likelihood\n\n\n\n\n\nThu, Apr 17\n\nLab 9 - Rhapsody in R\n\n\n\n\n\n15\nMon, Apr 21\n\nBayesian inference\n\n\n\n\n\nWed, Apr 23\n\nBayesian inference\n\nPSET 6 @ 3PM\n\n\n16\nSat, May 3\nsee…everything above\nFinal (7PM - 10PM)",
    "crumbs": [
      "Syllabus",
      "Schedule"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html",
    "href": "syllabus/syllabus_overview.html",
    "title": "Course overview",
    "section": "",
    "text": "We will spend roughly two thirds of the course on probability theory, and the last third on mathematical statistics. In probability, we describe the distribution of a random phenomenon and then study how the realizations of that phenomenon behave. In statistics, we do the reverse; we start with the realizations of a random phenomenon, and then try to figure out what distribution generated them. In this course, we will:\n\nlearn how to model random phenomena using a probability distribution, and learn how to extract from that distribution features and summaries that describe the phenomena’s “average” or “typical” behavior;\nlearn the mathematics necessary to pose and answer questions like: does this statistical procedure work? what does it mean for it to work? when does it work? how well does it work?\nwrite computer simulations to demonstrate the theoretical properties of probability distributions and statistical procedures;\nlearn how to analyze small, stylized datasets.\n\nPrerequisites: single-variable calculus.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#description",
    "href": "syllabus/syllabus_overview.html#description",
    "title": "Course overview",
    "section": "",
    "text": "We will spend roughly two thirds of the course on probability theory, and the last third on mathematical statistics. In probability, we describe the distribution of a random phenomenon and then study how the realizations of that phenomenon behave. In statistics, we do the reverse; we start with the realizations of a random phenomenon, and then try to figure out what distribution generated them. In this course, we will:\n\nlearn how to model random phenomena using a probability distribution, and learn how to extract from that distribution features and summaries that describe the phenomena’s “average” or “typical” behavior;\nlearn the mathematics necessary to pose and answer questions like: does this statistical procedure work? what does it mean for it to work? when does it work? how well does it work?\nwrite computer simulations to demonstrate the theoretical properties of probability distributions and statistical procedures;\nlearn how to analyze small, stylized datasets.\n\nPrerequisites: single-variable calculus.",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_overview.html#meetings",
    "href": "syllabus/syllabus_overview.html#meetings",
    "title": "Course overview",
    "section": "Meetings",
    "text": "Meetings\n\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\nStaff\n\n\n\n\nLectures\nSocial Sciences 136\nMoWe 3:05 PM - 4:20 PM\nJohn\n\n\nLab 01\nPerkins LINK 071 (Classroom 5)\nTh 1:25 PM - 2:40 PM\nGwen\n\n\nLab 02\nPerkins LINK 071 (Classroom 5)\nTh 3:05 PM - 4:20 PM\nGwen",
    "crumbs": [
      "Syllabus",
      "Overview"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html",
    "href": "syllabus/syllabus_resources.html",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#course-costs",
    "href": "syllabus/syllabus_resources.html#course-costs",
    "title": "University resources",
    "section": "",
    "text": "If you are having difficulty with the costs associated with this course (obtaining a laptop, mostly), here are some resources:\n\nKarsh Office of Undergraduate Support: Regardless of your aid package, Karsh offers loans and resources for connecting students with campus programs that might help alleviate course costs.\nDukeLIFE: The Course Material Assistance program offers assistance for eligible students, including through the LIFE Loaner Laptop Program. Students who are eligible for DukeLIFE benefits are notified before the start of the semester; program resources are limited.\nDuke Link: They have a small supply of laptops that can be rented out for five days at a time.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#tech-support",
    "href": "syllabus/syllabus_resources.html#tech-support",
    "title": "University resources",
    "section": "Tech support",
    "text": "Tech support\nContact the Duke OIT Service Desk at oit.duke.edu/help.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#academic-support",
    "href": "syllabus/syllabus_resources.html#academic-support",
    "title": "University resources",
    "section": "Academic support",
    "text": "Academic support\nThere are times you may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#accessibility",
    "href": "syllabus/syllabus_resources.html#accessibility",
    "title": "University resources",
    "section": "Accessibility",
    "text": "Accessibility\nIf any portion of the course is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students can engage with their courses and related assignments. Students should contact the SDAO to request or update accommodations under these circumstances.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "href": "syllabus/syllabus_resources.html#mental-health-and-well-being",
    "title": "University resources",
    "section": "Mental health and well-being",
    "text": "Mental health and well-being\nDuke is committed to holistic student well-being, including mental, emotional, and physical health. The university offers resources to help students manage daily stress, encourage intentional self-care, and access just-in-time support. If you find you need support, your mental and/or emotional health concerns are impacting your day-to-day activities and your academic performance, or you need someone to talk to, the resources below are available to you:\n\nDukeReach: DukeReach provides comprehensive outreach services to support students in managing all aspects of well-being, including referrals and follow-up services for students who are experiencing significant challenges related to mental health, physical health, social adjustment, and/or a variety of other stressors. You can reach the DukeReach team at dukereach@duke.edu.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. CAPS also provides referrals to off-campus resources for specialized care. You can reach CAPS at (919) 660-1000.\nTimelyCare: TimelyCare is an online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling.\nBC Fellows for Healthy Relationship: The BC Fellows meet with students individually and in groups, supporting the development of healthy relationships and building meaningful community in all areas of a student’s life.\nDukeLine: Students who want to connect anonymously with a Peer Coach can text 984-230-4888 from 5 to 11 p.m. daily. DukeLine offers in-the-moment anonymous, non-emergency text support from a peer.\nDuWell: DuWell provides Moments of Mindfulness (stress management and resilience building) and meditation programming (Koru workshop) to assist students in developing a daily emotional well-being practice. All are welcome, and no experience is necessary. You can reach DuWell at (919) 681-8421.",
    "crumbs": [
      "Syllabus",
      "University resources"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html",
    "href": "syllabus/syllabus_assignments.html",
    "title": "Assignments and grading",
    "section": "",
    "text": "Your final course grade will be calculated as follows:\nYour final letter grade will be determined based on these thresholds:",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#labs-10",
    "href": "syllabus/syllabus_assignments.html#labs-10",
    "title": "Assignments and grading",
    "section": "Labs (10%)",
    "text": "Labs (10%)\nIn lab every Thursday, you will complete a guided activity that illustrates how the latest course material can be applied to various domains of science and technology. Often this activity will also teach you how to implement some of the ideas from the course in the R programming language. Ideally you should be able to finish the activity by the end of your lab period, but in any case, you must submit your lab work by 11:59 ET PM that same day. Each lab problem will be graded for completion on the following scale:\n\n1.0: a complete, good faith attempt;\n0.5: partially complete;\n0.0: no submission, or mostly incomplete.\n\n\n\n\n\n\n\nNote\n\n\n\nYour two lowest lab scores will be dropped at the end of the semester.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#problem-sets-30",
    "href": "syllabus/syllabus_assignments.html#problem-sets-30",
    "title": "Assignments and grading",
    "section": "Problem Sets (30%)",
    "text": "Problem Sets (30%)\nMathematics is like everything else in life; if you practice, you improve. As such, the problem sets are really the heart of the course. They will mostly consist of pencil-and-paper math problems, but sometimes you will be asked to do some coding. You may compose you solutions however you like (scan or photograph written work, LaTeX, Quarto, handwriting capture on a tablet, whatever) so long as you ultimately upload a single .pdf file to Gradescope.\n\n\n\n\n\n\nNote\n\n\n\nYour lowest problem set score will be dropped at the end of the semester.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "syllabus/syllabus_assignments.html#exams-20-each",
    "href": "syllabus/syllabus_assignments.html#exams-20-each",
    "title": "Assignments and grading",
    "section": "Exams (20% each)",
    "text": "Exams (20% each)\nThese will be traditional, in-class, sit-down, written exams with no technology, and with no outside resources apart from a note sheet that you and only you have prepared (both sides of a standard 8.5” x 11” piece of paper).\n\n\n\n\n\n\nNote\n\n\n\nIf you do better on the final exam than you did on one of the midterms, we will replace your lowest midterm exam score with your final exam score.",
    "crumbs": [
      "Syllabus",
      "Assignments and grading"
    ]
  },
  {
    "objectID": "exams/midterm-1.html",
    "href": "exams/midterm-1.html",
    "title": "Extra Practice for Midterm 1",
    "section": "",
    "text": "On Monday February 17 during our usual class meeting, we have our first midterm exam. It will cover the following topics:\nBelow is a set of practice problems to help you prepare.",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-1",
    "href": "exams/midterm-1.html#problem-1",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 1",
    "text": "Problem 1\nLet \\(\\Omega\\) be the set of integers from 1 to 100, that is, \\(\\Omega = \\{1, 2, ..., 99, 100\\}\\). Let \\(E\\) be the subset of \\(\\Omega\\) that contains even numbers and \\(C = \\{1, 4, 9, 16, 25, 36, 49, 64, 81, 100\\}\\).\n\nList the elements in the set \\(E\\cap C\\).\nHow many elements are in \\(E\\cup C\\)?\nHow many elements are in \\((E\\cap C)^c\\)?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-2",
    "href": "exams/midterm-1.html#problem-2",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 2",
    "text": "Problem 2\nTake \\(\\mathbb{R}\\) to be your reference set and consider these subsets:\n\\[\n\\begin{align}\n    A & = \\mathbb{Z} = \\{\\dots,-2, -1, 0, 1, 2,\\dots\\}\\\\\n    B & = (0, 1)\\\\\n    C & = [0, \\infty).\n\\end{align}\n\\]\nExpress the following in as simplified and concise a form as possible:\n\n\\(A \\cap C\\)\n\\(B \\cup C^{c}\\)\n\\(B^{c} \\cap C\\)\n\\(A \\cap B \\cap C\\)",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-3",
    "href": "exams/midterm-1.html#problem-3",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 3",
    "text": "Problem 3\nLet \\(A\\) and \\(B\\) be two sets. Simplify the following expressions so that each set appears at most once in the final form:\n\n\\((A \\cup B) \\cap (A \\cup B^{c})\\)\n\\((A \\cup B) \\cap (A^{c} \\cup B) \\cap (A \\cup B^{c})\\)",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-4",
    "href": "exams/midterm-1.html#problem-4",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 4",
    "text": "Problem 4\nSuppose that \\(A\\) and \\(B\\) are mutually exclusive events for which \\(P(A) = 0.3\\) and \\(P(B) = 0.5\\). What is the probability that…\n\neither \\(A\\) or \\(B\\) occurs?\n\\(A\\) occurs but \\(B\\) does not?\nboth \\(A\\) and \\(B\\) occur?\nAre \\(A\\) and \\(B\\) independent? Why or why not?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-5",
    "href": "exams/midterm-1.html#problem-5",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 5",
    "text": "Problem 5\nOut of the students in a class, 60% are geniuses, 70% love chocolate, and 40% fall into both categories. Determine the probability that a randomly selected student is neither a genius nor a chocolate lover.",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-6",
    "href": "exams/midterm-1.html#problem-6",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 6",
    "text": "Problem 6\nIn the American version of the casino game roulette, the roulette wheel is divided into \\(38\\) spaces, namely the numbers \\(1\\) through \\(36\\) (even numbers colored red and odd colored black) and the special single zero and double zero (both colored green). Gamblers place bets on various groups of numbers and colors. The wheel is then spun one way, a ball is set in motion the other, and the ball eventually settles on one of the numbers – if the bet you placed included that number, you win! Let \\(X\\) be the number on which the ball settles.\nSuppose you know that the roulette wheel is not fair; in particular, you know that the probability that the ball settles on a particular zero is twice the probability the ball settles on a particular non-zero. That is to say,\n\\[\n\\mathbb{P}(X = x) =\n\\begin{cases}\np & \\text{if }x \\in \\{1, 2,\\dots, 36\\} \\\\\n2p & \\text{if }x \\in \\{0, 00\\},\n\\end{cases}\n\\] where \\(p \\in (0, 1)\\).\n\nYour statistically disinclined friend says, “Oh, okay. There are \\(38\\) possible values of \\(X\\), so \\(p = \\frac{1}{38}\\).” Explain why your friend is sorely mistaken.\nWhat is the value of \\(p\\)?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-7",
    "href": "exams/midterm-1.html#problem-7",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 7",
    "text": "Problem 7\nSuppose you have a set \\(A\\) of objects. The power set of \\(A\\) is defined to be the set of all possible subsets of \\(A\\).\n\nLet \\(A = \\{1, 3, 5\\}\\). What is the power set of \\(A\\)?\nSuppose \\(A\\) contains some number of items given by \\(N &gt; 0\\). How many sets are contained in the power set of \\(A\\)?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-8",
    "href": "exams/midterm-1.html#problem-8",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 8",
    "text": "Problem 8\nSuppose you have your trusty standard \\(52\\)-card deck on hand, and you deal out an eight-card hand. How many possible hands have…\n\nthree cards of one rank, four cards of another rank, and one card of yet another rank?\ntwo cards of each suit?\nat least one ace?\nno spades?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-9",
    "href": "exams/midterm-1.html#problem-9",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 9",
    "text": "Problem 9\nWe have now at this point the formulae for two- and three-way inclusion-exclusion, namely \\[P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\] and \\[P(A \\cup B \\cup C) = P(A) + P(B) + P(C) - P(A \\cap B) - P(A \\cap C) - P(B \\cap C) + P(A \\cap B \\cap C).\\] Explain in counting terms why we end up subtracting the two-way intersection in the first case and adding the three-way intersection in the second case.",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-10",
    "href": "exams/midterm-1.html#problem-10",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 10",
    "text": "Problem 10\nLet’s talk face cards. No, not those face cards – the boring kind. In a standard deck of \\(52\\) cards, 3 (Jack, Queen, and King) of the 13 ranks are collectively known as the ``face cards” of the deck. Recall that a standard deck of \\(52\\) cards also has \\(4\\) suits (Hearts, Diamonds, Clubs, and Spades).\nSuppose you deal out two cards from the deck. What is the probability that they are both face cards given that they are both hearts?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-11",
    "href": "exams/midterm-1.html#problem-11",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 11",
    "text": "Problem 11\nDisclaimer: The referenced party gave express permission to be used in this way. All numbers quoted are self-assessments, give or take. My Italian office mate is known to (1) watch football (in freedom units, that’s soccer) on his computer monitor and (2) yell at said monitor, sometimes simultaneously. In fact, if he’s watching a football match, there’s a \\(80\\%\\) chance he’ll be yelling at his monitor. At any rate, he only watches a match \\(10\\%\\) of the time, and he yells \\(40\\%\\) of the time that he’s not watching a match.\nGiven that I enter my office to his excited utterances, what is the probability that he is watching a football match?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-12",
    "href": "exams/midterm-1.html#problem-12",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 12",
    "text": "Problem 12\nSome of the greatest creations in the history of the universe have been born of mash-ups. You want breakfast and lunch? You got brunch! You want drama and comedy? You got dramedy! Perhaps the greatest mash-up of all: you want conditional probability and independent events? You got conditionally independent events!\nLet \\(A\\), \\(B\\), and \\(C\\) be events with \\(P(C) &gt; 0\\). \\(A\\) and \\(B\\) are conditionally independent given \\(C\\) if and only if\n\\[\nP(A \\cap B \\mid C) = P(A \\mid C)P(B \\mid C).\n\\]\nShow that the above implies \\(P(A \\mid B, C) = P(A \\mid C)\\).",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-13",
    "href": "exams/midterm-1.html#problem-13",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 13",
    "text": "Problem 13\nThe probability that a child in a given family will inherit a certain genetic mutation is 5%, and this probability is unaffected by the inheritance status of their siblings. Consider a family with 4 children.\n\nIf it is known that the first born has inherited the mutation, what is the expected number of children in the family who have inherited the mutation?\nIf it is known that at least one child has inherited the mutation, what is the expected number of children in the family who have inherited the mutation?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-14",
    "href": "exams/midterm-1.html#problem-14",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 14",
    "text": "Problem 14\nTwo balls are chosen randomly from an urn containing \\(9\\) green, \\(6\\) black, and \\(5\\) orange balls. Suppose that we win \\(\\$2\\) for each black ball selected, we lose \\(\\$1\\) for each green ball selected, and we earn nothing for each orange ball selected. Let \\(X\\) denote our winnings.\n\nMake a table listing the possible values of \\(X\\) and the probabilities associated with each value.\nCompute the expected value of \\(X\\).\nSketch the cdf and the pmf of \\(X\\).",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-15",
    "href": "exams/midterm-1.html#problem-15",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 15",
    "text": "Problem 15\nSuppose you have a sequence of independent \\(\\text{Bernoulli}(p)\\) trials; that is, each trial has probability \\(p\\) of success. We are interested in seeing how long it takes to observe a fixed number \\(r &gt; 0\\) of successes and thus repeat the trials until we observe \\(r\\) successes. Let \\(A\\) be the number of the trial at which we observe the \\(r\\)th success.\n\nWhat is the sample space of \\(A\\)?\nFix \\(n &gt; 0\\). What is the probability that we observe the \\(r\\)th success on the \\(n\\)th trial?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  },
  {
    "objectID": "exams/midterm-1.html#problem-16",
    "href": "exams/midterm-1.html#problem-16",
    "title": "Extra Practice for Midterm 1",
    "section": "Problem 16",
    "text": "Problem 16\nLet \\(D \\sim \\text{Geometric}(p)\\), and fix \\(n, k &gt; 0\\). What is \\(P(D = n + k \\,|\\, D &gt; k)\\)? Does this look familiar?",
    "crumbs": [
      "Labs",
      "Midterm 1 Practice"
    ]
  }
]